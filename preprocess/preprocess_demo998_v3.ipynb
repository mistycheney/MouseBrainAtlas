{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ENABLE_UPLOAD_S3 is not set, default to False.\n",
      "ENABLE_DOWNLOAD_S3 is not set, default to False.\n",
      "No vtk\n",
      "File does not exist: /data/CSHL_data_processed/DEMO999/DEMO999_anchor.txt\n",
      "File does not exist: /data/CSHL_data_processed/DEMO999/DEMO999_sorted_filenames.txt\n",
      "File does not exist: /data/CSHL_data_processed/DEMO999/DEMO999_sorted_filenames.txt\n",
      "File does not exist: /data/CSHL_data_processed/DEMO999/DEMO999_anchor.txt\n",
      "File does not exist: /data/CSHL_data_processed/DEMO999/DEMO999_anchor.txt\n",
      "File does not exist: /data/CSHL_data_processed/DEMO999/DEMO999_anchor.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting environment for Precision WorkStation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "\n",
    "sys.path.append(os.path.join(os.environ['REPO_DIR'], 'utilities'))\n",
    "from utilities2015 import *\n",
    "from metadata import *\n",
    "from data_manager import *\n",
    "from learning_utilities import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stack = 'DEMO998'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# **(HUMAN)** Create meta data information for this brain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%writefile DEMO998_config.ini\n",
    "[DEFAULT]\n",
    "planar_resolution_um = 0.46\n",
    "section_thickness_um = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get_all_images.py [stack] [input_spec_json]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_spec_json = '/home/yuncong/Brain/preprocess/DEMO998_input_spec.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ENABLE_UPLOAD_S3 is not set, default to False.\n",
      "ENABLE_DOWNLOAD_S3 is not set, default to False.\n",
      "Setting environment for Precision WorkStation\n",
      "No vtk\n",
      "File does not exist: /data/CSHL_data_processed/DEMO999/DEMO999_anchor.txt\n",
      "File does not exist: /data/CSHL_data_processed/DEMO999/DEMO999_sorted_filenames.txt\n",
      "File does not exist: /data/CSHL_data_processed/DEMO999/DEMO999_sorted_filenames.txt\n",
      "File does not exist: /data/CSHL_data_processed/DEMO999/DEMO999_anchor.txt\n",
      "File does not exist: /data/CSHL_data_processed/DEMO999/DEMO999_anchor.txt\n",
      "File does not exist: /data/CSHL_data_processed/DEMO999/DEMO999_anchor.txt\n",
      "Found 4 images.\n",
      "\n",
      "(None, u'raw') missing:\n",
      "set([])\n",
      "rm -f /tmp/stderr_*; rm -f /tmp/stdout_*\n",
      "return code: 0\n",
      "Run locally.\n",
      "Jobs submitted. Use wait_qsub_complete() to wait for all execution to finish.\n"
     ]
    }
   ],
   "source": [
    "! ./jp2_to_tiff.py DEMO998 {input_spec_json}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting /home/yuncong/Brain/preprocess/DEMO998_input_spec.ini\n"
     ]
    }
   ],
   "source": [
    "%%writefile /home/yuncong/Brain/preprocess/DEMO998_input_spec.ini\n",
    "[DEFAULT]\n",
    "version = None\n",
    "resolution = raw\n",
    "data_dir = /media/yuncong/BstemAtlasData/DEMO998\n",
    "filepath_to_imageName_mapping = /media/yuncong/BstemAtlasData/DEMO998/(.*)?_lossless.jp2\n",
    "imageName_to_filepath_mapping = /media/yuncong/BstemAtlasData/DEMO998/%%s_lossless.jp2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_spec_ini = '/home/yuncong/Brain/preprocess/DEMO998_input_spec.ini'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_ini(fp):\n",
    "    import configparser\n",
    "    config = configparser.ConfigParser()\n",
    "    config.read(fp)\n",
    "    input_spec = dict(config.items('DEFAULT'))\n",
    "    return input_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_input_spec(input_spec_json):\n",
    "    \n",
    "    input_spec = load_json(input_spec_json)\n",
    "    data_dirs = {}\n",
    "    filepath_to_imageName_mapping = {}\n",
    "    imageName_to_filepath_mapping = {}\n",
    "    for spec_one_version in input_spec:\n",
    "        vr = (spec_one_version['version'], spec_one_version['resolution'])\n",
    "        data_dirs[vr] = spec_one_version['data_dir']\n",
    "        filepath_to_imageName_mapping[vr] = spec_one_version['filepath_to_imageName_mapping']\n",
    "        imageName_to_filepath_mapping[vr] = spec_one_version['imageName_to_filepath_mapping']\n",
    "    \n",
    "    # search for all images\n",
    "\n",
    "    image_names_all_data_dirs_flattened = set([])\n",
    "    image_names_all_data_dirs = {}\n",
    "    for vr, data_dir in data_dirs.iteritems():\n",
    "        if data_dir is None: continue\n",
    "        image_names = set([])\n",
    "        if vr in filepath_to_imageName_mapping:\n",
    "            for fn in os.listdir(data_dir):\n",
    "                g = re.search(filepath_to_imageName_mapping[vr], os.path.join(data_dir, fn))\n",
    "                if g is not None:\n",
    "                    img_name = g.groups()[0]\n",
    "                    image_names.add(img_name)\n",
    "                    image_names_all_data_dirs_flattened.add(img_name)\n",
    "        image_names_all_data_dirs[vr] = image_names\n",
    "        \n",
    "    return {\n",
    "    'data_dirs': data_dirs,\n",
    "    'filepath_to_imageName_mapping': filepath_to_imageName_mapping,\n",
    "    'imageName_to_filepath_mapping': imageName_to_filepath_mapping,\n",
    "    'all_image_names': image_names_all_data_dirs_flattened,\n",
    "    'image_names_all_data_dirs': image_names_all_data_dirs\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_spec = parse_input_spec(input_spec_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4 images.\n",
      "\n",
      "(version, resolution) tuple (None, u'raw') does not have the follwing images:\n",
      "set([])\n"
     ]
    }
   ],
   "source": [
    "print \"Found %d images.\\n\" % len(input_spec['all_image_names'])\n",
    "\n",
    "# Make sure the every image has all three channels.\n",
    "for vr, img_names in input_spec['image_names_all_data_dirs'].iteritems():\n",
    "    print \"(version, resolution) tuple\", vr, 'does not have the follwing images:'\n",
    "    print input_spec['all_image_names'] - img_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# jp2_to_tiff.py [stack] [input_spec_json]\n",
    "# Expected output: tiff images of (none, raw) in the standard location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/data/CSHL_data_processed/DEMO998/DEMO998_raw'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_if_not_exists(DataManager.get_image_dir_v2(stack=stack, prep_id=None, resol='raw'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_image_names = list(input_spec['all_image_names'])\n",
    "imageName_to_filepath_mapping = input_spec['imageName_to_filepath_mapping']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "rm -f /tmp/stderr_*; rm -f /tmp/stdout_*\n",
      "return code: 0\n",
      "Run locally.\n",
      "Jobs submitted. Use wait_qsub_complete() to wait for all execution to finish.\n"
     ]
    }
   ],
   "source": [
    "# The KDU program automatically uses all cores, so we just set jobs_per_node = 1.\n",
    "run_distributed('export LD_LIBRARY_PATH=%(kdu_dir)s:$LD_LIBRARY_PATH; %(kdu_bin)s -i \\\"%%(in_fp)s\\\" -o \\\"%%(out_fp)s\\\"' % \\\n",
    "                {'kdu_bin': KDU_EXPAND_BIN, 'kdu_dir': os.path.dirname(KDU_EXPAND_BIN)},\n",
    "                kwargs_list={'in_fp': [imageName_to_filepath_mapping[(None, 'raw')] % img_name\n",
    "                                       for img_name in all_image_names],\n",
    "                             'out_fp': [DataManager.get_image_filepath_v2(stack=stack, prep_id=None,\n",
    "                                        resol='raw', version=None, fn=img_name)\n",
    "                                        for img_name in all_image_names]},\n",
    "                argument_type='single',\n",
    "                jobs_per_node=1,\n",
    "                local_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# extract_channel.py [input_spec] [channel] [out_version]\n",
    "# Expected output: Single-channel images of out_version in the standard location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting input_spec.ini\n"
     ]
    }
   ],
   "source": [
    "%%writefile input_spec.ini\n",
    "[DEFAULT]\n",
    "image_name_list = MD662&661-F102-2017.06.06-22.30.50_MD661_2_0305\n",
    "        MD662&661-F102-2017.06.06-22.30.50_MD661_1_0304\n",
    "        MD662&661-F101-2017.06.06-22.05.45_MD661_2_0302\n",
    "        MD662&661-F101-2017.06.06-22.05.45_MD661_1_0301\n",
    "stack = DEMO998\n",
    "prep_id = None\n",
    "version = None\n",
    "resol = raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ENABLE_UPLOAD_S3 is not set, default to False.\n",
      "ENABLE_DOWNLOAD_S3 is not set, default to False.\n",
      "Setting environment for Precision WorkStation\n",
      "No vtk\n",
      "File does not exist: /data/CSHL_data_processed/DEMO999/DEMO999_anchor.txt\n",
      "File does not exist: /data/CSHL_data_processed/DEMO999/DEMO999_sorted_filenames.txt\n",
      "File does not exist: /data/CSHL_data_processed/DEMO999/DEMO999_sorted_filenames.txt\n",
      "File does not exist: /data/CSHL_data_processed/DEMO999/DEMO999_anchor.txt\n",
      "File does not exist: /data/CSHL_data_processed/DEMO999/DEMO999_anchor.txt\n",
      "File does not exist: /data/CSHL_data_processed/DEMO999/DEMO999_anchor.txt\n",
      "rm -f /tmp/stderr_*; rm -f /tmp/stdout_*\n",
      "return code: 0\n",
      "Run locally.\n",
      "Jobs submitted. Use wait_qsub_complete() to wait for all execution to finish.\n"
     ]
    }
   ],
   "source": [
    "! python ./extract_channel.py input_spec.ini 2 Ntb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inputs = all_image_names # image name list (str list)\n",
    "channel = 2\n",
    "out_version = 'Ntb'\n",
    "\n",
    "# optional specifiers\n",
    "stack = 'DEMO999'\n",
    "prep_id = None\n",
    "resol = 'raw'\n",
    "in_version = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/data/CSHL_data_processed/DEMO999/DEMO999_raw_Ntb'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_if_not_exists(DataManager.get_image_dir_v2(stack=stack, prep_id=None, resol='raw', version=out_version))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "rm -f ~/stderr_*; rm -f ~/stdout_*\n",
      "return code: 0\n",
      "Run locally.\n",
      "Jobs submitted. Use wait_qsub_complete() to wait for all execution to finish.\n"
     ]
    }
   ],
   "source": [
    "run_distributed('convert \\\"%%(in_fp)s\\\" -channel %(channel)s -separate \\\"%%(out_fp)s\\\"' % {'channel': 'RGB'[channel]},\n",
    "                kwargs_list=[{'in_fp': DataManager.get_image_filepath_v2(stack=stack, prep_id=prep_id, \n",
    "                                        resol=resol, version=in_version, fn=img_name),\n",
    "                                       'out_fp': DataManager.get_image_filepath_v2(stack=stack, prep_id=prep_id, \n",
    "                                        resol=resol, version=out_version, fn=img_name)}\n",
    "                                       for img_name in all_image_names],\n",
    "                argument_type='single',\n",
    "                jobs_per_node=1,\n",
    "                local_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# rescale_image.py [input_spec] [[rescale_factor] | [width] [height]] [out_resol]\n",
    "# raw_Ntb -> thumbnail_Ntb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting temp.ini\n"
     ]
    }
   ],
   "source": [
    "%%writefile input_spec.ini\n",
    "[DEFAULT]\n",
    "image_name_list = MD662&661-F102-2017.06.06-22.30.50_MD661_2_0305\n",
    "        MD662&661-F102-2017.06.06-22.30.50_MD661_1_0304\n",
    "        MD662&661-F101-2017.06.06-22.05.45_MD661_2_0302\n",
    "        MD662&661-F101-2017.06.06-22.05.45_MD661_1_0301\n",
    "stack = DEMO998\n",
    "prep_id = None\n",
    "version = Ntb\n",
    "resol = raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ENABLE_UPLOAD_S3 is not set, default to False.\n",
      "ENABLE_DOWNLOAD_S3 is not set, default to False.\n",
      "Setting environment for Precision WorkStation\n",
      "No vtk\n",
      "File does not exist: /data/CSHL_data_processed/DEMO999/DEMO999_anchor.txt\n",
      "File does not exist: /data/CSHL_data_processed/DEMO999/DEMO999_sorted_filenames.txt\n",
      "File does not exist: /data/CSHL_data_processed/DEMO999/DEMO999_sorted_filenames.txt\n",
      "File does not exist: /data/CSHL_data_processed/DEMO999/DEMO999_anchor.txt\n",
      "File does not exist: /data/CSHL_data_processed/DEMO999/DEMO999_anchor.txt\n",
      "File does not exist: /data/CSHL_data_processed/DEMO999/DEMO999_anchor.txt\n",
      "/usr/local/lib/python2.7/dist-packages/skimage/io/_io.py:132: UserWarning: /data/CSHL_data_processed/DEMO998/DEMO998_thumbnail_Ntb/MD662&661-F102-2017.06.06-22.30.50_MD661_2_0305_thumbnail_Ntb.tif is a low contrast image\n",
      "  warn('%s is a low contrast image' % fname)\n",
      "Rescale: 1.75 seconds.\n",
      "/usr/local/lib/python2.7/dist-packages/skimage/io/_io.py:132: UserWarning: /data/CSHL_data_processed/DEMO998/DEMO998_thumbnail_Ntb/MD662&661-F102-2017.06.06-22.30.50_MD661_1_0304_thumbnail_Ntb.tif is a low contrast image\n",
      "  warn('%s is a low contrast image' % fname)\n",
      "Rescale: 1.89 seconds.\n",
      "/usr/local/lib/python2.7/dist-packages/skimage/io/_io.py:132: UserWarning: /data/CSHL_data_processed/DEMO998/DEMO998_thumbnail_Ntb/MD662&661-F101-2017.06.06-22.05.45_MD661_2_0302_thumbnail_Ntb.tif is a low contrast image\n",
      "  warn('%s is a low contrast image' % fname)\n",
      "Rescale: 1.73 seconds.\n",
      "/usr/local/lib/python2.7/dist-packages/skimage/io/_io.py:132: UserWarning: /data/CSHL_data_processed/DEMO998/DEMO998_thumbnail_Ntb/MD662&661-F101-2017.06.06-22.05.45_MD661_1_0301_thumbnail_Ntb.tif is a low contrast image\n",
      "  warn('%s is a low contrast image' % fname)\n",
      "Rescale: 1.66 seconds.\n"
     ]
    }
   ],
   "source": [
    "! python rescale.py input_spec.ini thumbnail -f {1./32}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inputs = all_image_names # image name list (str list)\n",
    "\n",
    "stack = 'DEMO999'\n",
    "prep_id = None\n",
    "in_resol = 'raw'\n",
    "version = 'Ntb'\n",
    "\n",
    "rescale_factor = 1./32\n",
    "out_resol = 'thumbnail'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/skimage/io/_io.py:132: UserWarning: /data/CSHL_data_processed/DEMO999/DEMO999_thumbnail_Ntb/MD662&661-F102-2017.06.06-22.30.50_MD661_2_0305_thumbnail_Ntb.tif is a low contrast image\n",
      "  warn('%s is a low contrast image' % fname)\n",
      "Rescale: 1.99 seconds.\n",
      "/usr/local/lib/python2.7/dist-packages/skimage/io/_io.py:132: UserWarning: /data/CSHL_data_processed/DEMO999/DEMO999_thumbnail_Ntb/MD662&661-F102-2017.06.06-22.30.50_MD661_1_0304_thumbnail_Ntb.tif is a low contrast image\n",
      "  warn('%s is a low contrast image' % fname)\n",
      "Rescale: 2.07 seconds.\n",
      "/usr/local/lib/python2.7/dist-packages/skimage/io/_io.py:132: UserWarning: /data/CSHL_data_processed/DEMO999/DEMO999_thumbnail_Ntb/MD662&661-F101-2017.06.06-22.05.45_MD661_2_0302_thumbnail_Ntb.tif is a low contrast image\n",
      "  warn('%s is a low contrast image' % fname)\n",
      "Rescale: 2.17 seconds.\n",
      "/usr/local/lib/python2.7/dist-packages/skimage/io/_io.py:132: UserWarning: /data/CSHL_data_processed/DEMO999/DEMO999_thumbnail_Ntb/MD662&661-F101-2017.06.06-22.05.45_MD661_1_0301_thumbnail_Ntb.tif is a low contrast image\n",
      "  warn('%s is a low contrast image' % fname)\n",
      "Rescale: 2.03 seconds.\n"
     ]
    }
   ],
   "source": [
    "for img_name in all_image_names:\n",
    "\n",
    "    t = time.time()\n",
    "\n",
    "    in_fp = DataManager.get_image_filepath_v2(stack=stack, prep_id=prep_id, resol=in_resol, version=version, fn=img_name)\n",
    "    out_fp = DataManager.get_image_filepath_v2(stack=stack, prep_id=prep_id, resol=out_resol, version=version, fn=img_name)\n",
    "    create_parent_dir_if_not_exists(out_fp)\n",
    "    \n",
    "    img = imread(in_fp)\n",
    "    \n",
    "    img_tb = img[::int(1./rescale_factor), ::int(1./rescale_factor)]\n",
    "    imsave(out_fp, img_tb)\n",
    "\n",
    "    # Alternative: ImageMagick introduces an artificial noisy stripe in the output image.\n",
    "#     cmd = 'convert %(in_fp)s -scale 3.125%% %(out_fp)s' % {'in_fp': in_fp, 'out_fp': out_fp}\n",
    "#     execute_command(cmd)\n",
    "        \n",
    "    sys.stderr.write(\"Rescale: %.2f seconds.\\n\" % (time.time() - t)) # ~20s / image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# normalize_intensity.py [input_spec] [out_version]\n",
    "# thumbnail_Ntb -> thumbnail_NtbNormalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: normalize_intensity.py [-h] input_spec out_version\r\n",
      "\r\n",
      "Linearly normalize intensity to between 0 and 255\r\n",
      "\r\n",
      "positional arguments:\r\n",
      "  input_spec   Input specification\r\n",
      "  out_version  Output image version\r\n",
      "\r\n",
      "optional arguments:\r\n",
      "  -h, --help   show this help message and exit\r\n"
     ]
    }
   ],
   "source": [
    "! python normalize_intensity.py -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting temp.ini\n"
     ]
    }
   ],
   "source": [
    "%%writefile input_spec.ini\n",
    "[DEFAULT]\n",
    "image_name_list = MD662&661-F102-2017.06.06-22.30.50_MD661_2_0305\n",
    "        MD662&661-F102-2017.06.06-22.30.50_MD661_1_0304\n",
    "        MD662&661-F101-2017.06.06-22.05.45_MD661_2_0302\n",
    "        MD662&661-F101-2017.06.06-22.05.45_MD661_1_0301\n",
    "stack = DEMO998\n",
    "prep_id = None\n",
    "version = Ntb\n",
    "resol = thumbnail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ENABLE_UPLOAD_S3 is not set, default to False.\n",
      "ENABLE_DOWNLOAD_S3 is not set, default to False.\n",
      "Setting environment for Precision WorkStation\n",
      "No vtk\n",
      "File does not exist: /data/CSHL_data_processed/DEMO999/DEMO999_anchor.txt\n",
      "File does not exist: /data/CSHL_data_processed/DEMO999/DEMO999_sorted_filenames.txt\n",
      "File does not exist: /data/CSHL_data_processed/DEMO999/DEMO999_sorted_filenames.txt\n",
      "File does not exist: /data/CSHL_data_processed/DEMO999/DEMO999_anchor.txt\n",
      "File does not exist: /data/CSHL_data_processed/DEMO999/DEMO999_anchor.txt\n",
      "File does not exist: /data/CSHL_data_processed/DEMO999/DEMO999_anchor.txt\n",
      "convert \"/data/CSHL_data_processed/DEMO998/DEMO998_thumbnail_Ntb/MD662&661-F102-2017.06.06-22.30.50_MD661_2_0305_thumbnail_Ntb.tif\" -normalize -depth 8 \"/data/CSHL_data_processed/DEMO998/DEMO998_thumbnail_NtbNormalized/MD662&661-F102-2017.06.06-22.30.50_MD661_2_0305_thumbnail_NtbNormalized.tif\" \n",
      "return code: 0\n",
      "Intensity normalize: 0.40 seconds.\n",
      "convert \"/data/CSHL_data_processed/DEMO998/DEMO998_thumbnail_Ntb/MD662&661-F102-2017.06.06-22.30.50_MD661_1_0304_thumbnail_Ntb.tif\" -normalize -depth 8 \"/data/CSHL_data_processed/DEMO998/DEMO998_thumbnail_NtbNormalized/MD662&661-F102-2017.06.06-22.30.50_MD661_1_0304_thumbnail_NtbNormalized.tif\" \n",
      "return code: 0\n",
      "Intensity normalize: 0.06 seconds.\n",
      "convert \"/data/CSHL_data_processed/DEMO998/DEMO998_thumbnail_Ntb/MD662&661-F101-2017.06.06-22.05.45_MD661_2_0302_thumbnail_Ntb.tif\" -normalize -depth 8 \"/data/CSHL_data_processed/DEMO998/DEMO998_thumbnail_NtbNormalized/MD662&661-F101-2017.06.06-22.05.45_MD661_2_0302_thumbnail_NtbNormalized.tif\" \n",
      "return code: 0\n",
      "Intensity normalize: 0.06 seconds.\n",
      "convert \"/data/CSHL_data_processed/DEMO998/DEMO998_thumbnail_Ntb/MD662&661-F101-2017.06.06-22.05.45_MD661_1_0301_thumbnail_Ntb.tif\" -normalize -depth 8 \"/data/CSHL_data_processed/DEMO998/DEMO998_thumbnail_NtbNormalized/MD662&661-F101-2017.06.06-22.05.45_MD661_1_0301_thumbnail_NtbNormalized.tif\" \n",
      "return code: 0\n",
      "Intensity normalize: 0.05 seconds.\n"
     ]
    }
   ],
   "source": [
    "! python normalize_intensity.py input_spec.ini NtbNormalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inputs = all_image_names # image name list (str list)\n",
    "\n",
    "stack = 'DEMO999'\n",
    "prep_id = None\n",
    "resol = 'thumbnail'\n",
    "in_version = 'Ntb'\n",
    "\n",
    "out_version = 'NtbNormalized'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "convert \"/data/CSHL_data_processed/DEMO999/DEMO999_thumbnail_Ntb/MD662&661-F102-2017.06.06-22.30.50_MD661_2_0305_thumbnail_Ntb.tif\" -normalize -depth 8 \"/data/CSHL_data_processed/DEMO999/DEMO999_thumbnail_NtbNormalized/MD662&661-F102-2017.06.06-22.30.50_MD661_2_0305_thumbnail_NtbNormalized.tif\" \n",
      "return code: 0\n",
      "Intensity normalize: 0.15 seconds.\n",
      "convert \"/data/CSHL_data_processed/DEMO999/DEMO999_thumbnail_Ntb/MD662&661-F102-2017.06.06-22.30.50_MD661_1_0304_thumbnail_Ntb.tif\" -normalize -depth 8 \"/data/CSHL_data_processed/DEMO999/DEMO999_thumbnail_NtbNormalized/MD662&661-F102-2017.06.06-22.30.50_MD661_1_0304_thumbnail_NtbNormalized.tif\" \n",
      "return code: 0\n",
      "Intensity normalize: 0.10 seconds.\n",
      "convert \"/data/CSHL_data_processed/DEMO999/DEMO999_thumbnail_Ntb/MD662&661-F101-2017.06.06-22.05.45_MD661_2_0302_thumbnail_Ntb.tif\" -normalize -depth 8 \"/data/CSHL_data_processed/DEMO999/DEMO999_thumbnail_NtbNormalized/MD662&661-F101-2017.06.06-22.05.45_MD661_2_0302_thumbnail_NtbNormalized.tif\" \n",
      "return code: 0\n",
      "Intensity normalize: 0.10 seconds.\n",
      "convert \"/data/CSHL_data_processed/DEMO999/DEMO999_thumbnail_Ntb/MD662&661-F101-2017.06.06-22.05.45_MD661_1_0301_thumbnail_Ntb.tif\" -normalize -depth 8 \"/data/CSHL_data_processed/DEMO999/DEMO999_thumbnail_NtbNormalized/MD662&661-F101-2017.06.06-22.05.45_MD661_1_0301_thumbnail_NtbNormalized.tif\" \n",
      "return code: 0\n",
      "Intensity normalize: 0.10 seconds.\n"
     ]
    }
   ],
   "source": [
    "for img_name in all_image_names:\n",
    "\n",
    "    t = time.time()\n",
    "\n",
    "    in_fp = DataManager.get_image_filepath_v2(stack=stack, prep_id=prep_id, resol=resol, version=in_version, fn=img_name)\n",
    "    out_fp = DataManager.get_image_filepath_v2(stack=stack, prep_id=prep_id, resol=resol, version=out_version, fn=img_name)\n",
    "    create_parent_dir_if_not_exists(out_fp)\n",
    "        \n",
    "    cmd = \"\"\"convert \"%(in_fp)s\" -normalize -depth 8 \"%(out_fp)s\" \"\"\" % {'in_fp': in_fp, 'out_fp': out_fp}\n",
    "    execute_command(cmd)\n",
    "    \n",
    "    sys.stderr.write(\"Intensity normalize: %.2f seconds.\\n\" % (time.time() - t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# **(HUMAN)**: browse thumbnails to verify orientations are all correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# align_compose_warp.py [input_specifiers] [anchor_img_name] [elastix_output_dir] [custom_output_dir]\n",
    "# thumbnail -> prep1_thumbnail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# (HUMAN) Obtain roughly correctly sorted list of image names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Step 1: Compute pairwise transforms.\n",
    "# align.py [input_spec] [elastix_output_dir] [param_fp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: align.py [-h] input_spec elastix_output_dir param_fp\r\n",
      "\r\n",
      "Align consecutive images. Possible bad alignment pairs are written into a separate file.\r\n",
      "\r\n",
      "positional arguments:\r\n",
      "  input_spec          txt. Each row is prev_img_name, prev_fp, curr_img_name,\r\n",
      "                      curr_fp\r\n",
      "  elastix_output_dir  output dir. Files for each pairwise transform are stored\r\n",
      "                      in sub-folder <currImageName>_to_<prevImageName>.\r\n",
      "  param_fp            elastix parameter file path\r\n",
      "\r\n",
      "optional arguments:\r\n",
      "  -h, --help          show this help message and exit\r\n"
     ]
    }
   ],
   "source": [
    "! python align.py -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting temp.ini\n"
     ]
    }
   ],
   "source": [
    "%%writefile input_spec.ini\n",
    "[DEFAULT]\n",
    "image_name_list = MD662&661-F101-2017.06.06-22.05.45_MD661_1_0301\n",
    "        MD662&661-F101-2017.06.06-22.05.45_MD661_2_0302\n",
    "        MD662&661-F102-2017.06.06-22.30.50_MD661_1_0304\n",
    "        MD662&661-F102-2017.06.06-22.30.50_MD661_2_0305\n",
    "stack = DEMO998\n",
    "prep_id = None\n",
    "version = NtbNormalized\n",
    "resol = thumbnail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "elastix_output_dir = os.path.join(THUMBNAIL_DATA_DIR, stack, stack + '_elastix_output')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param_fp = '/home/yuncong/Brain/preprocess/parameters/Parameters_Rigid_MutualInfo_noNumberOfSpatialSamples_4000Iters.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ENABLE_UPLOAD_S3 is not set, default to False.\n",
      "ENABLE_DOWNLOAD_S3 is not set, default to False.\n",
      "Setting environment for Precision WorkStation\n",
      "No vtk\n",
      "File does not exist: /data/CSHL_data_processed/DEMO999/DEMO999_anchor.txt\n",
      "File does not exist: /data/CSHL_data_processed/DEMO999/DEMO999_sorted_filenames.txt\n",
      "File does not exist: /data/CSHL_data_processed/DEMO999/DEMO999_sorted_filenames.txt\n",
      "File does not exist: /data/CSHL_data_processed/DEMO999/DEMO999_anchor.txt\n",
      "File does not exist: /data/CSHL_data_processed/DEMO999/DEMO999_anchor.txt\n",
      "File does not exist: /data/CSHL_data_processed/DEMO999/DEMO999_anchor.txt\n",
      "rm -f /tmp/stderr_*; rm -f /tmp/stdout_*\n",
      "return code: 0\n",
      "Run locally.\n",
      "Jobs submitted. Use wait_qsub_complete() to wait for all execution to finish.\n"
     ]
    }
   ],
   "source": [
    "! python align.py input_spec.ini {elastix_output_dir} {param_fp}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_image_names = all_image_names\n",
    "\n",
    "stack = 'DEMO999'\n",
    "resol = 'thumbnail'\n",
    "version = 'NtbNormalized'\n",
    "prep_id = None\n",
    "\n",
    "elastix_output_dir = os.path.join(THUMBNAIL_DATA_DIR, stack, stack + '_elastix_output')\n",
    "\n",
    "param_fp = '/home/yuncong/Brain/preprocess/parameters/Parameters_Rigid_MutualInfo_noNumberOfSpatialSamples_4000Iters.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_spec = 'DEMO999_align_input_spec.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "filelist = [(imgName, DataManager.get_image_filepath_v2(stack=stack, fn=imgName, \n",
    "                                                        prep_id=prep_id,\n",
    "                                                        resol=resol, version=version))\n",
    "             for imgName in input_image_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.savetxt(input_spec, filelist, fmt='%s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "filelist = np.loadtxt(input_spec, dtype=str).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Align...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "rm -f /tmp/stderr_*; rm -f /tmp/stdout_*\n",
      "return code: 0\n",
      "Run locally.\n",
      "Jobs submitted. Use wait_qsub_complete() to wait for all execution to finish.\n"
     ]
    }
   ],
   "source": [
    "t = time.time()\n",
    "print 'Align...'\n",
    "\n",
    "run_distributed(\"%(script)s \\\"%(output_dir)s\\\" \\'%%(kwargs_str)s\\' -p %(param_fp)s -r\" % \\\n",
    "                {'script': os.path.join(REPO_DIR, 'preprocess', 'align_sequential.py'),\n",
    "                'output_dir': elastix_output_dir,\n",
    "                 'param_fp': param_fp\n",
    "                },\n",
    "                kwargs_list=[{'prev_img_name': filelist[i-1][0],\n",
    "                              'curr_img_name': filelist[i][0],\n",
    "                              'prev_fp': filelist[i-1][1],\n",
    "                              'curr_fp': filelist[i][1],\n",
    "                             }\n",
    "                            for i in range(1, len(filelist))],\n",
    "                argument_type='list',\n",
    "                jobs_per_node=8,\n",
    "               local_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Step 2: Compose pairwise transforms to get each image's transform to the anchor image.\n",
    "# compose.py [elastix_output_dir] [custom_output_dir] [input_spec] [anchor_img_name] --out [toanchor_transforms_fp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: compose.py [-h] [--elastix_output_dir ELASTIX_OUTPUT_DIR]\r\n",
      "                  [--custom_output_dir CUSTOM_OUTPUT_DIR]\r\n",
      "                  [--input_spec INPUT_SPEC]\r\n",
      "                  [--anchor_img_name ANCHOR_IMG_NAME] [--out OUT]\r\n",
      "\r\n",
      "Generate a pkl file that stores a dict. Keys are image names and values are (3,3)-matrices.\r\n",
      "\r\n",
      "optional arguments:\r\n",
      "  -h, --help            show this help message and exit\r\n",
      "  --elastix_output_dir ELASTIX_OUTPUT_DIR\r\n",
      "  --custom_output_dir CUSTOM_OUTPUT_DIR\r\n",
      "  --input_spec INPUT_SPEC\r\n",
      "  --anchor_img_name ANCHOR_IMG_NAME\r\n",
      "  --out OUT\r\n"
     ]
    }
   ],
   "source": [
    "! python compose.py -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# (HUMAN) select anchor name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%writefile {DataManager.get_anchor_filename_filename(stack=stack)}\n",
    "MD662&661-F102-2017.06.06-22.30.50_MD661_1_0304"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "anchor_img_name = 'MD662&661-F102-2017.06.06-22.30.50_MD661_1_0304'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "elastix_output_dir = os.path.join(THUMBNAIL_DATA_DIR, stack, stack + '_elastix_output')\n",
    "custom_output_dir = os.path.join(THUMBNAIL_DATA_DIR, stack, stack + '_custom_output')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "toanchor_transforms_fp = os.path.join(DATA_DIR, stack, '%(stack)s_transformsTo_%(anchor_fn)s.csv' % \\\n",
    "                         dict(stack=stack, anchor_fn=anchor_img_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting input_spec.ini\n"
     ]
    }
   ],
   "source": [
    "%%writefile input_spec.ini\n",
    "[DEFAULT]\n",
    "image_name_list = MD662&661-F101-2017.06.06-22.05.45_MD661_1_0301\n",
    "        MD662&661-F101-2017.06.06-22.05.45_MD661_2_0302\n",
    "        MD662&661-F102-2017.06.06-22.30.50_MD661_1_0304\n",
    "        MD662&661-F102-2017.06.06-22.30.50_MD661_2_0305\n",
    "stack = DEMO998\n",
    "prep_id = None\n",
    "version = NtbNormalized\n",
    "resol = thumbnail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ENABLE_UPLOAD_S3 is not set, default to False.\n",
      "ENABLE_DOWNLOAD_S3 is not set, default to False.\n",
      "Setting environment for Precision WorkStation\n",
      "No vtk\n",
      "File does not exist: /data/CSHL_data_processed/DEMO999/DEMO999_anchor.txt\n",
      "File does not exist: /data/CSHL_data_processed/DEMO999/DEMO999_sorted_filenames.txt\n",
      "File does not exist: /data/CSHL_data_processed/DEMO999/DEMO999_sorted_filenames.txt\n",
      "File does not exist: /data/CSHL_data_processed/DEMO999/DEMO999_anchor.txt\n",
      "File does not exist: /data/CSHL_data_processed/DEMO999/DEMO999_anchor.txt\n",
      "File does not exist: /data/CSHL_data_processed/DEMO999/DEMO999_anchor.txt\n",
      "Load elastix-computed transform: /data/CSHL_data_processed/DEMO998/DEMO998_elastix_output/MD662&661-F101-2017.06.06-22.05.45_MD661_2_0302_to_MD662&661-F101-2017.06.06-22.05.45_MD661_1_0301/TransformParameters.0.txt\n",
      "Load elastix-computed transform: /data/CSHL_data_processed/DEMO998/DEMO998_elastix_output/MD662&661-F102-2017.06.06-22.30.50_MD661_1_0304_to_MD662&661-F101-2017.06.06-22.05.45_MD661_2_0302/TransformParameters.0.txt\n",
      "Load elastix-computed transform: /data/CSHL_data_processed/DEMO998/DEMO998_elastix_output/MD662&661-F102-2017.06.06-22.30.50_MD661_2_0305_to_MD662&661-F102-2017.06.06-22.30.50_MD661_1_0304/TransformParameters.0.txt\n",
      "0 MD662&661-F101-2017.06.06-22.05.45_MD661_1_0301 [[ 9.99843536e-01 -1.76890774e-02  2.56612817e+01]\n",
      " [ 1.76890774e-02  9.99843536e-01 -5.02095432e+01]\n",
      " [ 0.00000000e+00  0.00000000e+00  1.00000000e+00]]\n",
      "1 MD662&661-F101-2017.06.06-22.05.45_MD661_2_0302 [[  0.9988451   -0.0480465   30.71635875]\n",
      " [  0.0480465    0.9988451  -46.31107527]\n",
      " [  0.           0.           1.        ]]\n",
      "2 MD662&661-F102-2017.06.06-22.30.50_MD661_1_0304 [[1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]]\n",
      "3 MD662&661-F102-2017.06.06-22.30.50_MD661_2_0305 [[ 9.99383040e-01 -3.51217753e-02  6.43498487e+01]\n",
      " [ 3.51217753e-02  9.99383040e-01 -2.28854706e+01]\n",
      " [ 0.00000000e+00  0.00000000e+00  1.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "! python compose.py --elastix_output_dir \"{elastix_output_dir}\" \\\n",
    "--custom_output_dir \"{custom_output_dir}\" \\\n",
    "--input_spec input_spec.ini  \\\n",
    "--anchor \"{anchor_img_name}\" \\\n",
    "--out \"{toanchor_transforms_fp}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "elastix_output_dir = os.path.join(THUMBNAIL_DATA_DIR, stack, stack + '_elastix_output')\n",
    "custom_output_dir = os.path.join(THUMBNAIL_DATA_DIR, stack, stack + '_custom_output')\n",
    "input_spec = 'DEMO999_align_input_spec.txt'\n",
    "anchor_img_name = 'MD662&661-F102-2017.06.06-22.30.50_MD661_1_0304'\n",
    "\n",
    "# [optional]\n",
    "toanchor_transforms_fp = os.path.join(DATA_DIR, stack, '%(stack)s_transformsTo_%(anchor_fn)s.csv' % \\\n",
    "                         dict(stack=stack, anchor_fn=anchor_img_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "image_name_list = [img_name for img_name, fp in np.loadtxt(input_spec, dtype=str).tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 525,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 MD662&661-F102-2017.06.06-22.30.50_MD661_2_0305 [[ 9.99380157e-01 -3.52037246e-02  6.43611476e+01]\n",
      " [ 3.52037246e-02  9.99380157e-01 -2.29074725e+01]\n",
      " [ 0.00000000e+00  0.00000000e+00  1.00000000e+00]]\n",
      "1 MD662&661-F102-2017.06.06-22.30.50_MD661_1_0304 [[1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]]\n",
      "2 MD662&661-F101-2017.06.06-22.05.45_MD661_2_0302 [[  0.99884395  -0.04807047  30.73029782]\n",
      " [  0.04807047   0.99884395 -46.30303942]\n",
      " [  0.           0.           1.        ]]\n",
      "3 MD662&661-F101-2017.06.06-22.05.45_MD661_1_0301 [[ 9.99843164e-01 -1.77100741e-02  2.56495999e+01]\n",
      " [ 1.77100741e-02  9.99843164e-01 -5.02563325e+01]\n",
      " [ 0.00000000e+00  0.00000000e+00  1.00000000e+00]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Load elastix-computed transform: /data/CSHL_data_processed/DEMO999/DEMO999_elastix_output/MD662&661-F102-2017.06.06-22.30.50_MD661_1_0304_to_MD662&661-F102-2017.06.06-22.30.50_MD661_2_0305/TransformParameters.0.txt\n",
      "Load elastix-computed transform: /data/CSHL_data_processed/DEMO999/DEMO999_elastix_output/MD662&661-F101-2017.06.06-22.05.45_MD661_2_0302_to_MD662&661-F102-2017.06.06-22.30.50_MD661_1_0304/TransformParameters.0.txt\n",
      "Load elastix-computed transform: /data/CSHL_data_processed/DEMO999/DEMO999_elastix_output/MD662&661-F101-2017.06.06-22.05.45_MD661_1_0301_to_MD662&661-F101-2017.06.06-22.05.45_MD661_2_0302/TransformParameters.0.txt\n"
     ]
    }
   ],
   "source": [
    "anchor_idx = image_name_list.index(anchor_img_name)\n",
    "\n",
    "transformation_to_previous_sec = {}\n",
    "\n",
    "for i in range(1, len(image_name_list)):\n",
    "\n",
    "    transformation_to_previous_sec[i] = DataManager.load_consecutive_section_transform(moving_fn=image_name_list[i], fixed_fn=image_name_list[i-1], elastix_output_dir=elastix_output_dir, custom_output_dir=custom_output_dir)\n",
    "\n",
    "transformation_to_anchor_sec = {}\n",
    "\n",
    "for moving_idx in range(len(image_name_list)):\n",
    "\n",
    "    if moving_idx == anchor_idx:\n",
    "        # transformation_to_anchor_sec[moving_idx] = np.eye(3)\n",
    "        transformation_to_anchor_sec[image_name_list[moving_idx]] = np.eye(3)\n",
    "\n",
    "    elif moving_idx < anchor_idx:\n",
    "        T_composed = np.eye(3)\n",
    "        for i in range(anchor_idx, moving_idx, -1):\n",
    "            T_composed = np.dot(np.linalg.inv(transformation_to_previous_sec[i]), T_composed)\n",
    "        # transformation_to_anchor_sec[moving_idx] = T_composed\n",
    "        transformation_to_anchor_sec[image_name_list[moving_idx]] = T_composed\n",
    "\n",
    "    else:\n",
    "        T_composed = np.eye(3)\n",
    "        for i in range(anchor_idx+1, moving_idx+1):\n",
    "            T_composed = np.dot(transformation_to_previous_sec[i], T_composed)\n",
    "        # transformation_to_anchor_sec[moving_idx] = T_composed\n",
    "        transformation_to_anchor_sec[image_name_list[moving_idx]] = T_composed\n",
    "\n",
    "    print moving_idx, image_name_list[moving_idx], transformation_to_anchor_sec[image_name_list[moving_idx]]\n",
    "\n",
    "#################################################\n",
    "\n",
    "# with open(toanchor_transforms_fp, 'w') as f:\n",
    "#     pickle.dump(transformation_to_anchor_sec, f)\n",
    "    # Note that the index starts at 0, BUT the .._renamed folder index starts at 1.\n",
    "                                                                                     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 526,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dict_to_csv(transformation_to_anchor_sec, toanchor_transforms_fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# (HUMAN) set planar_resolution for DEMO998 in metadata.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Step 3: thumbnail -> prep1_thumbnail\n",
    "\n",
    "# Single image\n",
    "# warp_crop.py [input_fp] [output_fp] [--warp transform_str] [--crop box_xywh_str] [--pad_color pad_color]\n",
    "\n",
    "# Multiple images\n",
    "# warp_crop.py [input_spec] [out_prep_id] [--warp transforms_pkl] [--crop cropbox_json] [--pad_color pad_color]\n",
    "\n",
    "# transforms_pkl: pickle of a Python dict. Keys are image names, values are (3,3) matrices that represent the transformations to the anchor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: warp_crop.py [-h] [--input_spec INPUT_SPEC] [--out_prep_id OUT_PREP_ID]\r\n",
      "                    [--input_fp INPUT_FP] [--output_fp OUTPUT_FP]\r\n",
      "                    [--warp WARP] [--inverse_warp INVERSE_WARP] [--crop CROP]\r\n",
      "                    [--pad_color PAD_COLOR] [-r INIT_ROTATE]\r\n",
      "\r\n",
      "Warp and crop images.\r\n",
      "\r\n",
      "optional arguments:\r\n",
      "  -h, --help            show this help message and exit\r\n",
      "  --input_spec INPUT_SPEC\r\n",
      "                        json\r\n",
      "  --out_prep_id OUT_PREP_ID\r\n",
      "                        if not specified, assume None\r\n",
      "  --input_fp INPUT_FP   input filepath\r\n",
      "  --output_fp OUTPUT_FP\r\n",
      "                        output filepath\r\n",
      "  --warp WARP           pkl for multiple images or csv_str for one image\r\n",
      "  --inverse_warp INVERSE_WARP\r\n",
      "                        pkl for multiple images or csv_str for one image\r\n",
      "  --crop CROP           json or box_xywh_str\r\n",
      "  --pad_color PAD_COLOR\r\n",
      "                        background color (black or white)\r\n",
      "  -r INIT_ROTATE, --init_rotate INIT_ROTATE\r\n",
      "                        escaped imagemagick convert option string for initial\r\n",
      "                        flipping and rotation\r\n"
     ]
    }
   ],
   "source": [
    "! python warp_crop.py -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting input_spec.ini\n"
     ]
    }
   ],
   "source": [
    "%%writefile input_spec.ini\n",
    "[DEFAULT]\n",
    "image_name_list = MD662&661-F101-2017.06.06-22.05.45_MD661_1_0301\n",
    "        MD662&661-F101-2017.06.06-22.05.45_MD661_2_0302\n",
    "        MD662&661-F102-2017.06.06-22.30.50_MD661_1_0304\n",
    "        MD662&661-F102-2017.06.06-22.30.50_MD661_2_0305\n",
    "stack = DEMO998\n",
    "prep_id = None\n",
    "version = NtbNormalized\n",
    "resol = thumbnail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ENABLE_UPLOAD_S3 is not set, default to False.\n",
      "ENABLE_DOWNLOAD_S3 is not set, default to False.\n",
      "Setting environment for Precision WorkStation\n",
      "No vtk\n",
      "File does not exist: /data/CSHL_data_processed/DEMO999/DEMO999_anchor.txt\n",
      "File does not exist: /data/CSHL_data_processed/DEMO999/DEMO999_sorted_filenames.txt\n",
      "File does not exist: /data/CSHL_data_processed/DEMO999/DEMO999_sorted_filenames.txt\n",
      "File does not exist: /data/CSHL_data_processed/DEMO999/DEMO999_anchor.txt\n",
      "File does not exist: /data/CSHL_data_processed/DEMO999/DEMO999_anchor.txt\n",
      "File does not exist: /data/CSHL_data_processed/DEMO999/DEMO999_anchor.txt\n",
      "rm -f /tmp/stderr_*; rm -f /tmp/stdout_*\n",
      "return code: 0\n",
      "Run locally.\n",
      "Jobs submitted. Use wait_qsub_complete() to wait for all execution to finish.\n"
     ]
    }
   ],
   "source": [
    "! python warp_crop.py --input_spec input_spec.ini \\\n",
    " --warp \"/data/CSHL_data_processed/DEMO999/DEMO999_transformsTo_MD662&661-F102-2017.06.06-22.30.50_MD661_1_0304.csv\" \\\n",
    " --out_prep_id alignedPadded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cropbox_to_list(cropbox):\n",
    "    return np.array([cropbox['rostral_limit'], cropbox['dorsal_limit'], cropbox['caudal_limit'] -  cropbox['rostral_limit'] + 1, cropbox['ventral_limit'] -  cropbox['dorsal_limit'] + 1])\n",
    "\n",
    "def list_to_str(s):\n",
    "    return ','.join(map(str, s))\n",
    "\n",
    "def cropbox_to_str(cropbox):\n",
    "    return list_to_str(cropbox_to_list(cropbox))\n",
    "\n",
    "def transform_to_str(transform):\n",
    "    return ','.join(map(str, transform.flatten()))\n",
    "\n",
    "def str_to_transform(transform_str):\n",
    "    return np.reshape(map(np.float, transform_str.split(',')), (3,3))\n",
    "\n",
    "def str_to_cropbox(cropbox_str):\n",
    "    return map(int, map(eval, cropbox_str.split(',')))\n",
    "\n",
    "def rescale_transform(transform, factor):\n",
    "\n",
    "    T = transform.copy()\n",
    "    T[:2,2] = transform[:2, 2] * factor\n",
    "    return T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "out_prep_id = 'alignedBrainstemCrop'\n",
    "init_rotate = ''\n",
    "pad_color = 'auto' # useful for alternatively stained stacks where bg varies depending on stain on each section\n",
    "\n",
    "transforms_pkl = '/data/CSHL_data_processed/DEMO999/DEMO999_transformsTo_MD662&661-F102-2017.06.06-22.30.50_MD661_1_0304.pkl'\n",
    "warp = transforms_pkl\n",
    "\n",
    "cropbox_json = '/data/CSHL_data_processed/DEMO999/DEMO999_alignedTo_MD662&661-F116-2017.06.07-04.39.41_MD661_1_0346_prep2_cropbox.json'\n",
    "crop = cropbox_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# input_spec = 'DEMO999_align_input_spec.txt'\n",
    "input_spec = 'DEMO999_align_input_spec_v2.ini'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:3: DeprecationWarning: You passed a bytestring as `filenames`. This will not work on Python 3. Use `cp.read_file()` or switch to using Unicode strings across the board.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "import configparser\n",
    "config = configparser.ConfigParser()\n",
    "config.read(input_spec)\n",
    "input_spec = dict(config.items('DEFAULT'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "image_name_list = input_spec['image_name_list'].split('\\n')\n",
    "stack = input_spec['stack']\n",
    "prep_id = input_spec['prep_id']\n",
    "version = input_spec['version']\n",
    "resol = input_spec['resol']\n",
    "\n",
    "# image_name_list = [img_name for img_name, fp in  np.loadtxt(input_spec, dtype=str).tolist()]\n",
    "# stack = 'DEMO999'\n",
    "# prep_id = None\n",
    "# version = 'NtbNormalized'\n",
    "# resol = 'thumbnail'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "rm -f /tmp/stderr_*; rm -f /tmp/stdout_*\n",
      "return code: 0\n",
      "Run locally.\n",
      "Jobs submitted. Use wait_qsub_complete() to wait for all execution to finish.\n"
     ]
    }
   ],
   "source": [
    "assert warp.endswith('.csv')\n",
    "transforms_to_anchor = load_pickle(warp)\n",
    "\n",
    "transforms_resol = 'thumbnail'\n",
    "\n",
    "transforms_scale_factor = convert_resolution_string_to_um(stack=stack, resolution=transforms_resol) / convert_resolution_string_to_um(stack=stack, resolution=resol)\n",
    "cropbox_scale_factor = convert_resolution_string_to_um(stack=stack, resolution=cropbox_resol) / convert_resolution_string_to_um(stack=stack, resolution=resol)\n",
    "\n",
    "run_distributed('%(script)s --input_fp \\\"%%(input_fp)s\\\" --output_fp \\\"%%(output_fp)s\\\" --warp %%(transform_str)s --crop %%(box_xywh_str)s --pad_color %%(pad_color)s' % \\\n",
    "            {'script': os.path.join(REPO_DIR, 'preprocess', 'warp_crop.py'),\n",
    "            },\n",
    "            kwargs_list=[{'transform_str': transform_to_str(rescale_transform(transforms_to_anchor[img_name], factor=transforms_scale_factor)),\n",
    "                      'box_xywh_str': list_to_str(cropbox_to_list(cropbox) * cropbox_scale_factor),\n",
    "                    'input_fp': DataManager.get_image_filepath_v2(stack=stack, fn=img_name, prep_id=None, version=version, resol=resol),\n",
    "                      'output_fp': DataManager.get_image_filepath_v2(stack=stack, fn=img_name, prep_id=out_prep_id, version=version, resol=resol),\n",
    "                        'pad_color': ('black' if img_name.split('-')[1][0] == 'F' else 'white') if pad_color == 'auto' else pad_color}\n",
    "                            for img_name in image_name_list],\n",
    "            argument_type='single',\n",
    "           jobs_per_node=8,\n",
    "        local_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "image_name = 'MD662&661-F101-2017.06.06-22.05.45_MD661_2_0302'\n",
    "\n",
    "input_fp = DataManager.get_image_filepath_v2(stack=stack, fn=image_name, prep_id=prep_id, version=version, resol=resol)\n",
    "\n",
    "output_fp = DataManager.get_image_filepath_v2(stack=stack, fn=image_name, prep_id=out_prep_id, version=version, resol=resol)\n",
    "create_parent_dir_if_not_exists(output_fp)\n",
    "\n",
    "transforms_to_anchor = load_pickle(transforms_pkl)\n",
    "transform_str = transform_to_str(transforms_to_anchor[image_name])\n",
    "\n",
    "cropbox_str = cropbox_to_str(load_json(cropbox_json))\n",
    "\n",
    "warp = transform_str\n",
    "crop = cropbox_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "convert \"/data/CSHL_data_processed/DEMO999/DEMO999_thumbnail_NtbNormalized/MD662&661-F101-2017.06.06-22.05.45_MD661_2_0302_thumbnail_NtbNormalized.tif\"  +repage -virtual-pixel background -background auto +distort AffineProjection '0.998844,-0.048070,0.048070,0.998844,-28.468963,47.726730' -crop 777x492+468+129\\! -flatten -compress lzw \"/data/CSHL_data_processed/DEMO999/DEMO999_prep2_thumbnail_NtbNormalized/MD662&661-F101-2017.06.06-22.05.45_MD661_2_0302_prep2_thumbnail_NtbNormalized.tif\"\n",
      "return code: 0\n"
     ]
    }
   ],
   "source": [
    "if init_rotate == '':\n",
    "    init_rotate = ''\n",
    "else:\n",
    "    init_rotate = orientation_argparse_str_to_imagemagick_str[init_rotate]\n",
    "\n",
    "T = np.linalg.inv(str_to_transform(warp))\n",
    "x, y, w, h = str_to_cropbox(crop)\n",
    "\n",
    "execute_command(\"convert \\\"%(input_fp)s\\\" %(init_rotate)s +repage -virtual-pixel background -background %(bg_color)s +distort AffineProjection '%(sx)f,%(rx)f,%(ry)f,%(sy)f,%(tx)f,%(ty)f' -crop %(w)sx%(h)s%(x)s%(y)s\\! -flatten -compress lzw \\\"%(output_fp)s\\\"\" % \\\n",
    "            {'init_rotate':init_rotate,\n",
    "                'sx':T[0,0],\n",
    " 'sy':T[1,1],\n",
    " 'rx':T[1,0],\n",
    "'ry':T[0,1],\n",
    " 'tx':T[0,2],\n",
    " 'ty':T[1,2],\n",
    " 'input_fp': input_fp,\n",
    " 'output_fp': output_fp,\n",
    " 'x': '+' + str(x) if int(x) >= 0 else str(x),\n",
    " 'y': '+' + str(y) if int(y) >= 0 else str(y),\n",
    " 'w': str(w),\n",
    "'h': str(h),\n",
    " 'bg_color': pad_color\n",
    "}\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# **(HUMAN)** Inspect aligned images using preprocessGUI, correct pairwise transforms and check each image's order in stack. `preprocess_gui.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (HUMAN) create DEMO998_sorted_filenames.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting /data/CSHL_data_processed/DEMO998/DEMO998_sorted_filenames.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile {DataManager.get_sorted_filenames_filename(stack=stack)}\n",
    "MD662&661-F101-2017.06.06-22.05.45_MD661_1_0301 1\n",
    "MD662&661-F101-2017.06.06-22.05.45_MD661_2_0302 2\n",
    "MD662&661-F102-2017.06.06-22.30.50_MD661_1_0304 3\n",
    "MD662&661-F102-2017.06.06-22.30.50_MD661_2_0305 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# (HUMAN) draw initial snake contours for masking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ENABLE_UPLOAD_S3 is not set, default to False.\n",
      "ENABLE_DOWNLOAD_S3 is not set, default to False.\n",
      "Setting environment for Precision WorkStation\n",
      "No vtk\n",
      "File does not exist: /data/CSHL_data_processed/DEMO999/DEMO999_anchor.txt\n",
      "File does not exist: /data/CSHL_data_processed/DEMO999/DEMO999_sorted_filenames.txt\n",
      "File does not exist: /data/CSHL_data_processed/DEMO999/DEMO999_sorted_filenames.txt\n",
      "File does not exist: /data/CSHL_data_processed/DEMO999/DEMO999_anchor.txt\n",
      "File does not exist: /data/CSHL_data_processed/DEMO999/DEMO999_anchor.txt\n",
      "File does not exist: /data/CSHL_data_processed/DEMO999/DEMO999_anchor.txt\n",
      "usage: masking.py [-h] [--min_size MIN_SIZE]\n",
      "                  [--default_channel DEFAULT_CHANNEL] [--shrink SHRINK]\n",
      "                  input_spec init_snake_contours_fp\n",
      "\n",
      "Generate masks for aligned thumbnail images\n",
      "\n",
      "positional arguments:\n",
      "  input_spec            stack name\n",
      "  init_snake_contours_fp\n",
      "                        initial snake contour file path\n",
      "\n",
      "optional arguments:\n",
      "  -h, --help            show this help message and exit\n",
      "  --min_size MIN_SIZE   minimum submask size\n",
      "  --default_channel DEFAULT_CHANNEL\n",
      "                        default RGB channel to do snake on; ignored if input\n",
      "                        images are single-channel\n",
      "  --shrink SHRINK       shrink strength or lambda1 in morphsnake paper,\n",
      "                        default 1\n"
     ]
    }
   ],
   "source": [
    "! python masking.py -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting input_spec.ini\n"
     ]
    }
   ],
   "source": [
    "%%writefile input_spec.ini\n",
    "[DEFAULT]\n",
    "image_name_list = MD662&661-F101-2017.06.06-22.05.45_MD661_1_0301\n",
    "        MD662&661-F101-2017.06.06-22.05.45_MD661_2_0302\n",
    "        MD662&661-F102-2017.06.06-22.30.50_MD661_1_0304\n",
    "        MD662&661-F102-2017.06.06-22.30.50_MD661_2_0305\n",
    "stack = DEMO998\n",
    "prep_id = alignedPadded\n",
    "version = NtbNormalized\n",
    "resol = thumbnail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ENABLE_UPLOAD_S3 is not set, default to False.\n",
      "ENABLE_DOWNLOAD_S3 is not set, default to False.\n",
      "Setting environment for Precision WorkStation\n",
      "No vtk\n",
      "File does not exist: /data/CSHL_data_processed/DEMO999/DEMO999_anchor.txt\n",
      "File does not exist: /data/CSHL_data_processed/DEMO999/DEMO999_sorted_filenames.txt\n",
      "File does not exist: /data/CSHL_data_processed/DEMO999/DEMO999_sorted_filenames.txt\n",
      "File does not exist: /data/CSHL_data_processed/DEMO999/DEMO999_anchor.txt\n",
      "File does not exist: /data/CSHL_data_processed/DEMO999/DEMO999_anchor.txt\n",
      "File does not exist: /data/CSHL_data_processed/DEMO999/DEMO999_anchor.txt\n",
      "Trying to load /data/CSHL_data_processed/DEMO998/DEMO998_prep1_thumbnail_NtbNormalized/MD662&661-F101-2017.06.06-22.05.45_MD661_1_0301_prep1_thumbnail_NtbNormalized.tif\n",
      "Trying to load /data/CSHL_data_processed/DEMO998/DEMO998_prep1_thumbnail_NtbNormalized/MD662&661-F101-2017.06.06-22.05.45_MD661_2_0302_prep1_thumbnail_NtbNormalized.tif\n",
      "Trying to load /data/CSHL_data_processed/DEMO998/DEMO998_prep1_thumbnail_NtbNormalized/MD662&661-F102-2017.06.06-22.30.50_MD661_1_0304_prep1_thumbnail_NtbNormalized.tif\n",
      "Trying to load /data/CSHL_data_processed/DEMO998/DEMO998_prep1_thumbnail_NtbNormalized/MD662&661-F102-2017.06.06-22.30.50_MD661_2_0305_prep1_thumbnail_NtbNormalized.tif\n",
      "123(1 percentile), 254(99 percentile)\n",
      "125(1 percentile), 254(99 percentile)\n",
      "123(1 percentile), 254(99 percentile)\n",
      "106(1 percentile), 254(99 percentile)\n",
      "Found 1 levelsets.\n",
      "\n",
      "Contour 0\n",
      "Found 1 levelsets.\n",
      "\n",
      "Contour 0\n",
      "Found 1 levelsets.\n",
      "\n",
      "Contour 0\n",
      "Found 1 levelsets.\n",
      "\n",
      "Contour 0\n",
      "Component area is too small - nullified.\n",
      "Component area is too small - nullified.\n",
      "Component area is too small - nullified.\n",
      "Component area is too small - nullified.\n",
      "Component area is too small - nullified.\n",
      "Component area is too small - nullified.\n",
      "Component area is too small - nullified.\n",
      "Component area is too small - nullified.\n",
      "Component area is too small - nullified.\n",
      "Component area is too small - nullified.\n",
      "Component area is too small - nullified.\n",
      "Component area is too small - nullified.\n",
      "Component area is too small - nullified.\n",
      "Component area is too small - nullified.\n",
      "Component area is too small - nullified.\n",
      "Component area is too small - nullified.\n",
      "Component area is too small - nullified.\n",
      "Component area is too small - nullified.\n",
      "Component area is too small - nullified.\n",
      "Component area is too small - nullified.\n",
      "Component area is too small - nullified.\n",
      "Component area is too small - nullified.\n",
      "Component area is too small - nullified.\n",
      "Component area is too small - nullified.\n",
      "Component area is too small - nullified.\n",
      "Component area is too small - nullified.\n",
      "Component area is too small - nullified.\n",
      "Component area is too small - nullified.\n",
      "Component area is too small - nullified.\n",
      "Component area is too small - nullified.\n",
      "Component area is too small - nullified.\n",
      "Component area is too small - nullified.\n",
      "Component area is too small - nullified.\n",
      "Component area is too small - nullified.\n",
      "Component area is too small - nullified.\n",
      "Component area is too small - nullified.\n",
      "Component area is too small - nullified.\n",
      "Component area is too small - nullified.\n",
      "Component area is too small - nullified.\n",
      "Component area is too small - nullified.\n",
      "Component area is too small - nullified.\n",
      "Component area is too small - nullified.\n",
      "Component area is too small - nullified.\n",
      "Component area is too small - nullified.\n",
      "Component area is too small - nullified.\n",
      "Component area is too small - nullified.\n",
      "Component area is too small - nullified.\n",
      "Component area is too small - nullified.\n",
      "Component area is too small - nullified.\n",
      "Component area is too small - nullified.\n",
      "Component area is too small - nullified.\n",
      "Component area is too small - nullified.\n",
      "Component area is too small - nullified.\n",
      "Component area is too small - nullified.\n",
      "Component area is too small - nullified.\n",
      "Component area is too small - nullified.\n",
      "Component area is too small - nullified.\n",
      "Component area is too small - nullified.\n",
      "Component area is too small - nullified.\n",
      "Component area is too small - nullified.\n",
      "Component area is too small - nullified.\n",
      "Component area is too small - nullified.\n",
      "Component area is too small - nullified.\n",
      "Component area is too small - nullified.\n",
      "Component area is too small - nullified.\n",
      "Component area is too small - nullified.\n",
      "Component area is too small - nullified.\n",
      "Component area is too small - nullified.\n",
      "Snake finished at iteration 177.\n",
      "Snake: 36.64 seconds\n",
      "Final masks added.\n",
      "aws s3 cp \"/data/CSHL_data_processed/DEMO998/DEMO998_prep1_thumbnail_autoSubmasks/MD662&661-F102-2017.06.06-22.30.50_MD661_1_0304/MD662&661-F102-2017.06.06-22.30.50_MD661_1_0304_prep1_thumbnail_autoSubmask_0.png\" \"s3://mousebrainatlas-data/CSHL_data_processed/DEMO998/DEMO998_prep1_thumbnail_autoSubmasks/MD662&661-F102-2017.06.06-22.30.50_MD661_1_0304/MD662&661-F102-2017.06.06-22.30.50_MD661_1_0304_prep1_thumbnail_autoSubmask_0.png\"\n",
      "upload: ../../../../data/CSHL_data_processed/DEMO998/DEMO998_prep1_thumbnail_autoSubmasks/MD662&661-F102-2017.06.06-22.30.50_MD661_1_0304/MD662&661-F102-2017.06.06-22.30.50_MD661_1_0304_prep1_thumbnail_autoSubmask_0.png to s3://mousebrainatlas-data/CSHL_data_processed/DEMO998/DEMO998_prep1_thumbnail_autoSubmasks/MD662&661-F102-2017.06.06-22.30.50_MD661_1_0304/MD662&661-F102-2017.06.06-22.30.50_MD661_1_0304_prep1_thumbnail_autoSubmask_0.png\n",
      "return code: 0\n",
      "aws s3 cp \"/data/CSHL_data_processed/DEMO998/DEMO998_prep1_thumbnail_autoSubmasks/MD662&661-F102-2017.06.06-22.30.50_MD661_1_0304/MD662&661-F102-2017.06.06-22.30.50_MD661_1_0304_prep1_thumbnail_autoSubmaskDecisions.csv\" \"s3://mousebrainatlas-data/CSHL_data_processed/DEMO998/DEMO998_prep1_thumbnail_autoSubmasks/MD662&661-F102-2017.06.06-22.30.50_MD661_1_0304/MD662&661-F102-2017.06.06-22.30.50_MD661_1_0304_prep1_thumbnail_autoSubmaskDecisions.csv\"\n",
      "upload: ../../../../data/CSHL_data_processed/DEMO998/DEMO998_prep1_thumbnail_autoSubmasks/MD662&661-F102-2017.06.06-22.30.50_MD661_1_0304/MD662&661-F102-2017.06.06-22.30.50_MD661_1_0304_prep1_thumbnail_autoSubmaskDecisions.csv to s3://mousebrainatlas-data/CSHL_data_processed/DEMO998/DEMO998_prep1_thumbnail_autoSubmasks/MD662&661-F102-2017.06.06-22.30.50_MD661_1_0304/MD662&661-F102-2017.06.06-22.30.50_MD661_1_0304_prep1_thumbnail_autoSubmaskDecisions.csv\n",
      "return code: 0\n",
      "Component area is too small - nullified.\n",
      "Snake finished at iteration 200.\n",
      "Snake: 40.68 seconds\n",
      "Final masks added.\n",
      "aws s3 cp \"/data/CSHL_data_processed/DEMO998/DEMO998_prep1_thumbnail_autoSubmasks/MD662&661-F101-2017.06.06-22.05.45_MD661_1_0301/MD662&661-F101-2017.06.06-22.05.45_MD661_1_0301_prep1_thumbnail_autoSubmask_0.png\" \"s3://mousebrainatlas-data/CSHL_data_processed/DEMO998/DEMO998_prep1_thumbnail_autoSubmasks/MD662&661-F101-2017.06.06-22.05.45_MD661_1_0301/MD662&661-F101-2017.06.06-22.05.45_MD661_1_0301_prep1_thumbnail_autoSubmask_0.png\"\n",
      "upload: ../../../../data/CSHL_data_processed/DEMO998/DEMO998_prep1_thumbnail_autoSubmasks/MD662&661-F101-2017.06.06-22.05.45_MD661_1_0301/MD662&661-F101-2017.06.06-22.05.45_MD661_1_0301_prep1_thumbnail_autoSubmask_0.png to s3://mousebrainatlas-data/CSHL_data_processed/DEMO998/DEMO998_prep1_thumbnail_autoSubmasks/MD662&661-F101-2017.06.06-22.05.45_MD661_1_0301/MD662&661-F101-2017.06.06-22.05.45_MD661_1_0301_prep1_thumbnail_autoSubmask_0.png\n",
      "return code: 0\n",
      "aws s3 cp \"/data/CSHL_data_processed/DEMO998/DEMO998_prep1_thumbnail_autoSubmasks/MD662&661-F101-2017.06.06-22.05.45_MD661_1_0301/MD662&661-F101-2017.06.06-22.05.45_MD661_1_0301_prep1_thumbnail_autoSubmaskDecisions.csv\" \"s3://mousebrainatlas-data/CSHL_data_processed/DEMO998/DEMO998_prep1_thumbnail_autoSubmasks/MD662&661-F101-2017.06.06-22.05.45_MD661_1_0301/MD662&661-F101-2017.06.06-22.05.45_MD661_1_0301_prep1_thumbnail_autoSubmaskDecisions.csv\"\n",
      "upload: ../../../../data/CSHL_data_processed/DEMO998/DEMO998_prep1_thumbnail_autoSubmasks/MD662&661-F101-2017.06.06-22.05.45_MD661_1_0301/MD662&661-F101-2017.06.06-22.05.45_MD661_1_0301_prep1_thumbnail_autoSubmaskDecisions.csv to s3://mousebrainatlas-data/CSHL_data_processed/DEMO998/DEMO998_prep1_thumbnail_autoSubmasks/MD662&661-F101-2017.06.06-22.05.45_MD661_1_0301/MD662&661-F101-2017.06.06-22.05.45_MD661_1_0301_prep1_thumbnail_autoSubmaskDecisions.csv\n",
      "return code: 0\n",
      "Snake finished at iteration 205.\n",
      "Snake: 42.13 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final masks added.\n",
      "aws s3 cp \"/data/CSHL_data_processed/DEMO998/DEMO998_prep1_thumbnail_autoSubmasks/MD662&661-F101-2017.06.06-22.05.45_MD661_2_0302/MD662&661-F101-2017.06.06-22.05.45_MD661_2_0302_prep1_thumbnail_autoSubmask_0.png\" \"s3://mousebrainatlas-data/CSHL_data_processed/DEMO998/DEMO998_prep1_thumbnail_autoSubmasks/MD662&661-F101-2017.06.06-22.05.45_MD661_2_0302/MD662&661-F101-2017.06.06-22.05.45_MD661_2_0302_prep1_thumbnail_autoSubmask_0.png\"\n",
      "upload: ../../../../data/CSHL_data_processed/DEMO998/DEMO998_prep1_thumbnail_autoSubmasks/MD662&661-F101-2017.06.06-22.05.45_MD661_2_0302/MD662&661-F101-2017.06.06-22.05.45_MD661_2_0302_prep1_thumbnail_autoSubmask_0.png to s3://mousebrainatlas-data/CSHL_data_processed/DEMO998/DEMO998_prep1_thumbnail_autoSubmasks/MD662&661-F101-2017.06.06-22.05.45_MD661_2_0302/MD662&661-F101-2017.06.06-22.05.45_MD661_2_0302_prep1_thumbnail_autoSubmask_0.png\n",
      "return code: 0\n",
      "aws s3 cp \"/data/CSHL_data_processed/DEMO998/DEMO998_prep1_thumbnail_autoSubmasks/MD662&661-F101-2017.06.06-22.05.45_MD661_2_0302/MD662&661-F101-2017.06.06-22.05.45_MD661_2_0302_prep1_thumbnail_autoSubmaskDecisions.csv\" \"s3://mousebrainatlas-data/CSHL_data_processed/DEMO998/DEMO998_prep1_thumbnail_autoSubmasks/MD662&661-F101-2017.06.06-22.05.45_MD661_2_0302/MD662&661-F101-2017.06.06-22.05.45_MD661_2_0302_prep1_thumbnail_autoSubmaskDecisions.csv\"\n",
      "upload: ../../../../data/CSHL_data_processed/DEMO998/DEMO998_prep1_thumbnail_autoSubmasks/MD662&661-F101-2017.06.06-22.05.45_MD661_2_0302/MD662&661-F101-2017.06.06-22.05.45_MD661_2_0302_prep1_thumbnail_autoSubmaskDecisions.csv to s3://mousebrainatlas-data/CSHL_data_processed/DEMO998/DEMO998_prep1_thumbnail_autoSubmasks/MD662&661-F101-2017.06.06-22.05.45_MD661_2_0302/MD662&661-F101-2017.06.06-22.05.45_MD661_2_0302_prep1_thumbnail_autoSubmaskDecisions.csv\n",
      "return code: 0\n",
      "Snake finished at iteration 219.\n",
      "Snake: 44.88 seconds\n",
      "Final masks added.\n",
      "aws s3 cp \"/data/CSHL_data_processed/DEMO998/DEMO998_prep1_thumbnail_autoSubmasks/MD662&661-F102-2017.06.06-22.30.50_MD661_2_0305/MD662&661-F102-2017.06.06-22.30.50_MD661_2_0305_prep1_thumbnail_autoSubmask_0.png\" \"s3://mousebrainatlas-data/CSHL_data_processed/DEMO998/DEMO998_prep1_thumbnail_autoSubmasks/MD662&661-F102-2017.06.06-22.30.50_MD661_2_0305/MD662&661-F102-2017.06.06-22.30.50_MD661_2_0305_prep1_thumbnail_autoSubmask_0.png\"\n",
      "upload: ../../../../data/CSHL_data_processed/DEMO998/DEMO998_prep1_thumbnail_autoSubmasks/MD662&661-F102-2017.06.06-22.30.50_MD661_2_0305/MD662&661-F102-2017.06.06-22.30.50_MD661_2_0305_prep1_thumbnail_autoSubmask_0.png to s3://mousebrainatlas-data/CSHL_data_processed/DEMO998/DEMO998_prep1_thumbnail_autoSubmasks/MD662&661-F102-2017.06.06-22.30.50_MD661_2_0305/MD662&661-F102-2017.06.06-22.30.50_MD661_2_0305_prep1_thumbnail_autoSubmask_0.png\n",
      "return code: 0\n",
      "aws s3 cp \"/data/CSHL_data_processed/DEMO998/DEMO998_prep1_thumbnail_autoSubmasks/MD662&661-F102-2017.06.06-22.30.50_MD661_2_0305/MD662&661-F102-2017.06.06-22.30.50_MD661_2_0305_prep1_thumbnail_autoSubmaskDecisions.csv\" \"s3://mousebrainatlas-data/CSHL_data_processed/DEMO998/DEMO998_prep1_thumbnail_autoSubmasks/MD662&661-F102-2017.06.06-22.30.50_MD661_2_0305/MD662&661-F102-2017.06.06-22.30.50_MD661_2_0305_prep1_thumbnail_autoSubmaskDecisions.csv\"\n",
      "upload: ../../../../data/CSHL_data_processed/DEMO998/DEMO998_prep1_thumbnail_autoSubmasks/MD662&661-F102-2017.06.06-22.30.50_MD661_2_0305/MD662&661-F102-2017.06.06-22.30.50_MD661_2_0305_prep1_thumbnail_autoSubmaskDecisions.csv to s3://mousebrainatlas-data/CSHL_data_processed/DEMO998/DEMO998_prep1_thumbnail_autoSubmasks/MD662&661-F102-2017.06.06-22.30.50_MD661_2_0305/MD662&661-F102-2017.06.06-22.30.50_MD661_2_0305_prep1_thumbnail_autoSubmaskDecisions.csv\n",
      "return code: 0\n",
      "Generate contours: 46.51\n"
     ]
    }
   ],
   "source": [
    "! python masking.py input_spec.ini {DataManager.get_initial_snake_contours_filepath(stack=stack)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#(HUMAN) Return to masking GUI to inspect and correct the automatically generated masks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# prep1_thumbnail_mask -> thumbnail_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: warp_crop.py [-h] [--input_spec INPUT_SPEC] [--out_prep_id OUT_PREP_ID]\r\n",
      "                    [--input_fp INPUT_FP] [--output_fp OUTPUT_FP]\r\n",
      "                    [--warp WARP] [--inverse_warp INVERSE_WARP] [--crop CROP]\r\n",
      "                    [--pad_color PAD_COLOR] [-r INIT_ROTATE]\r\n",
      "\r\n",
      "Warp and crop images.\r\n",
      "\r\n",
      "optional arguments:\r\n",
      "  -h, --help            show this help message and exit\r\n",
      "  --input_spec INPUT_SPEC\r\n",
      "                        json\r\n",
      "  --out_prep_id OUT_PREP_ID\r\n",
      "                        if not specified, assume None\r\n",
      "  --input_fp INPUT_FP   input filepath\r\n",
      "  --output_fp OUTPUT_FP\r\n",
      "                        output filepath\r\n",
      "  --warp WARP           pkl for multiple images or csv_str for one image\r\n",
      "  --inverse_warp INVERSE_WARP\r\n",
      "                        pkl for multiple images or csv_str for one image\r\n",
      "  --crop CROP           json or box_xywh_str\r\n",
      "  --pad_color PAD_COLOR\r\n",
      "                        background color (black or white)\r\n",
      "  -r INIT_ROTATE, --init_rotate INIT_ROTATE\r\n",
      "                        escaped imagemagick convert option string for initial\r\n",
      "                        flipping and rotation\r\n"
     ]
    }
   ],
   "source": [
    "! python warp_crop.py --help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting input_spec.ini\n"
     ]
    }
   ],
   "source": [
    "%%writefile input_spec.ini\n",
    "[DEFAULT]\n",
    "image_name_list = MD662&661-F101-2017.06.06-22.05.45_MD661_1_0301\n",
    "        MD662&661-F101-2017.06.06-22.05.45_MD661_2_0302\n",
    "        MD662&661-F102-2017.06.06-22.30.50_MD661_1_0304\n",
    "        MD662&661-F102-2017.06.06-22.30.50_MD661_2_0305\n",
    "stack = DEMO998\n",
    "prep_id = alignedPadded\n",
    "version = mask\n",
    "resol = thumbnail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trying to load /data/CSHL_data_processed/DEMO998/DEMO998_thumbnail_NtbNormalized/MD662&661-F101-2017.06.06-22.05.45_MD661_1_0301_thumbnail_NtbNormalized.tif\n",
      "Trying to load /data/CSHL_data_processed/DEMO998/DEMO998_thumbnail_NtbNormalized/MD662&661-F101-2017.06.06-22.05.45_MD661_2_0302_thumbnail_NtbNormalized.tif\n",
      "Trying to load /data/CSHL_data_processed/DEMO998/DEMO998_thumbnail_NtbNormalized/MD662&661-F102-2017.06.06-22.30.50_MD661_1_0304_thumbnail_NtbNormalized.tif\n",
      "Trying to load /data/CSHL_data_processed/DEMO998/DEMO998_thumbnail_NtbNormalized/MD662&661-F102-2017.06.06-22.30.50_MD661_2_0305_thumbnail_NtbNormalized.tif\n"
     ]
    }
   ],
   "source": [
    "d = {img_name: \\\n",
    " (0,0) + DataManager.load_image_v2(stack=stack, prep_id=None, resol='thumbnail', version='NtbNormalized', fn=img_name).shape[::-1]\n",
    " for img_name in \n",
    "    [\n",
    "        'MD662&661-F101-2017.06.06-22.05.45_MD661_1_0301',\n",
    "        'MD662&661-F101-2017.06.06-22.05.45_MD661_2_0302',\n",
    "        'MD662&661-F102-2017.06.06-22.30.50_MD661_1_0304',\n",
    "        'MD662&661-F102-2017.06.06-22.30.50_MD661_2_0305',\n",
    "    ]}\n",
    "\n",
    "df = pd.DataFrame.from_dict({k: np.array(v).flatten() for k, v in d.iteritems()}, orient='index')\n",
    "df.to_csv('/data/CSHL_data_processed/DEMO998/DEMO998_original_image_crop.csv', header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ENABLE_UPLOAD_S3 is not set, default to False.\n",
      "ENABLE_DOWNLOAD_S3 is not set, default to False.\n",
      "Setting environment for Precision WorkStation\n",
      "No vtk\n",
      "File does not exist: /data/CSHL_data_processed/DEMO999/DEMO999_anchor.txt\n",
      "File does not exist: /data/CSHL_data_processed/DEMO999/DEMO999_sorted_filenames.txt\n",
      "File does not exist: /data/CSHL_data_processed/DEMO999/DEMO999_sorted_filenames.txt\n",
      "File does not exist: /data/CSHL_data_processed/DEMO999/DEMO999_anchor.txt\n",
      "File does not exist: /data/CSHL_data_processed/DEMO999/DEMO999_anchor.txt\n",
      "File does not exist: /data/CSHL_data_processed/DEMO999/DEMO999_anchor.txt\n",
      "rm -f /tmp/stderr_*; rm -f /tmp/stdout_*\n",
      "return code: 0\n",
      "Run locally.\n",
      "Jobs submitted. Use wait_qsub_complete() to wait for all execution to finish.\n"
     ]
    }
   ],
   "source": [
    "! python warp_crop.py --input_spec input_spec.ini \\\n",
    " --inverse_warp \"{toanchor_transforms_fp}\" \\\n",
    " --crop \"/data/CSHL_data_processed/DEMO998/DEMO998_original_image_crop.csv\" \\\n",
    " --out_prep_id None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Brighfield correction\n",
    "# normalize_intensity_adaptive.py [input_spec] [out_version]\n",
    "# raw_Ntb -> raw_NtbNormalizedAdaptiveInvertedGamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: normalize_intensity_adaptive.py [-h] input_spec out_version\r\n",
      "\r\n",
      "Linearly normalize intensity to between 0 and 255\r\n",
      "\r\n",
      "positional arguments:\r\n",
      "  input_spec   Input specification\r\n",
      "  out_version  Output image version\r\n",
      "\r\n",
      "optional arguments:\r\n",
      "  -h, --help   show this help message and exit\r\n"
     ]
    }
   ],
   "source": [
    "! python normalize_intensity_adaptive.py --help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting input_spec.ini\n"
     ]
    }
   ],
   "source": [
    "%%writefile input_spec.ini\n",
    "[DEFAULT]\n",
    "image_name_list = MD662&661-F101-2017.06.06-22.05.45_MD661_1_0301\n",
    "        MD662&661-F101-2017.06.06-22.05.45_MD661_2_0302\n",
    "        MD662&661-F102-2017.06.06-22.30.50_MD661_1_0304\n",
    "        MD662&661-F102-2017.06.06-22.30.50_MD661_2_0305\n",
    "stack = DEMO998\n",
    "prep_id = None\n",
    "version = Ntb\n",
    "resol = raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ENABLE_UPLOAD_S3 is not set, default to False.\n",
      "ENABLE_DOWNLOAD_S3 is not set, default to False.\n",
      "Setting environment for Precision WorkStation\n",
      "No vtk\n",
      "File does not exist: /data/CSHL_data_processed/DEMO999/DEMO999_anchor.txt\n",
      "File does not exist: /data/CSHL_data_processed/DEMO999/DEMO999_sorted_filenames.txt\n",
      "File does not exist: /data/CSHL_data_processed/DEMO999/DEMO999_sorted_filenames.txt\n",
      "File does not exist: /data/CSHL_data_processed/DEMO999/DEMO999_anchor.txt\n",
      "File does not exist: /data/CSHL_data_processed/DEMO999/DEMO999_anchor.txt\n",
      "File does not exist: /data/CSHL_data_processed/DEMO999/DEMO999_anchor.txt\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/home/yuncong/Brain/utilities/utilities2015.py:131: DeprecationWarning: You passed a bytestring as `filenames`. This will not work on Python 3. Use `cp.read_file()` or switch to using Unicode strings across the board.\n",
      "  config.read(fp)\n",
      "/usr/local/lib/python2.7/dist-packages/skimage/util/dtype.py:122: UserWarning: Possible precision loss when converting from float64 to uint8\n",
      "  .format(dtypeobj_in, dtypeobj_out))\n",
      "Rescale to uint8: 25.24 seconds.\n",
      "Load mask: 1.45 seconds.\n",
      "Rescale to uint8: 24.55 seconds.\n",
      "Load mask: 2.00 seconds.\n",
      "Rescale to uint8: 29.77 seconds.\n",
      "Load mask: 2.11 seconds.\n",
      "Rescale to uint8: 30.03 seconds.\n",
      "Load mask: 2.68 seconds.\n"
     ]
    }
   ],
   "source": [
    "! python normalize_intensity_adaptive.py input_spec.ini NtbNormalizedAdaptiveInvertedGamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "out_version = 'NtbNormalizedAdaptiveInvertedGamma'\n",
    "\n",
    "image_name_list = all_image_names\n",
    "stack = 'DEMO999'\n",
    "prep_id = None\n",
    "version = 'Ntb'\n",
    "resol = 'raw'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.ndimage.interpolation import map_coordinates\n",
    "from skimage.exposure import rescale_intensity, adjust_gamma\n",
    "from skimage.transform import rotate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image MD662&661-F102-2017.06.06-22.30.50_MD661_2_0305\n",
      "Image MD662&661-F102-2017.06.06-22.30.50_MD661_1_0304\n",
      "Image MD662&661-F101-2017.06.06-22.05.45_MD661_2_0302\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trying to load /data/CSHL_data_processed/DEMO999/DEMO999_thumbnail_Ntb/MD662&661-F102-2017.06.06-22.30.50_MD661_2_0305_thumbnail_Ntb.tif\n",
      "Load image: 0.00 seconds.\n",
      "Compute mean/std for sample regions: 0.03 seconds.\n",
      "Interpolate mean map: 0.01 seconds.\n",
      "Scale up mean map: 0.02 seconds.\n",
      "Interpolate std map: 0.01 seconds.\n",
      "Scale up std map: 0.02 seconds.\n",
      "Normalize: 0.01 seconds.\n",
      "Trying to load /data/CSHL_data_processed/DEMO999/DEMO999_thumbnail_Ntb/MD662&661-F102-2017.06.06-22.30.50_MD661_1_0304_thumbnail_Ntb.tif\n",
      "Load image: 0.00 seconds.\n",
      "Compute mean/std for sample regions: 0.02 seconds.\n",
      "Interpolate mean map: 0.01 seconds.\n",
      "Scale up mean map: 0.02 seconds.\n",
      "Interpolate std map: 0.01 seconds.\n",
      "Scale up std map: 0.02 seconds.\n",
      "Normalize: 0.01 seconds.\n",
      "Trying to load /data/CSHL_data_processed/DEMO999/DEMO999_thumbnail_Ntb/MD662&661-F101-2017.06.06-22.05.45_MD661_2_0302_thumbnail_Ntb.tif\n",
      "Load image: 0.00 seconds.\n",
      "Compute mean/std for sample regions: 0.02 seconds.\n",
      "Interpolate mean map: 0.01 seconds.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image MD662&661-F101-2017.06.06-22.05.45_MD661_1_0301\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scale up mean map: 0.01 seconds.\n",
      "Interpolate std map: 0.01 seconds.\n",
      "Scale up std map: 0.01 seconds.\n",
      "Normalize: 0.01 seconds.\n",
      "Trying to load /data/CSHL_data_processed/DEMO999/DEMO999_thumbnail_Ntb/MD662&661-F101-2017.06.06-22.05.45_MD661_1_0301_thumbnail_Ntb.tif\n",
      "Load image: 0.00 seconds.\n",
      "Compute mean/std for sample regions: 0.02 seconds.\n",
      "Interpolate mean map: 0.01 seconds.\n",
      "Scale up mean map: 0.01 seconds.\n",
      "Interpolate std map: 0.01 seconds.\n",
      "Scale up std map: 0.01 seconds.\n",
      "Normalize: 0.01 seconds.\n"
     ]
    }
   ],
   "source": [
    "# for section in set(metadata_cache['valid_sections_all'][stack]) - set(metadata_cache['valid_sections'][stack]):\n",
    "for image_name in all_image_names:\n",
    "    \n",
    "    print \"Image\", image_name\n",
    "    \n",
    "    t = time.time()\n",
    "    \n",
    "    img = DataManager.load_image_v2(stack=stack, prep_id=None, fn=image_name, version='Ntb', resol='thumbnail')\n",
    "\n",
    "    sys.stderr.write('Load image: %.2f seconds.\\n' % (time.time() - t))\n",
    "\n",
    "#     t = time.time()\n",
    "    tb_mask = DataManager.load_thumbnail_mask_v3(stack=stack, prep_id=None, fn=image_name)\n",
    "# #     raw_mask = rescale_by_resampling(tb_mask, new_shape=(img.shape[1], img.shape[0]))\n",
    "#     raw_mask = resize(tb_mask, img.shape) > .5\n",
    "    \n",
    "#     save_data(raw_mask, \n",
    "#           DataManager.get_image_filepath_v2(stack=stack, prep_id=None, section=section, version='mask', resol='raw', ext='bp'), \n",
    "#           upload_s3=False)\n",
    "    \n",
    "#     sys.stderr.write('Rescale mask: %.2f seconds.\\n' % (time.time() - t))\n",
    "\n",
    "    t = time.time()\n",
    "    \n",
    "    mean_std_all_regions = []\n",
    "    cx_cy_all_regions = []\n",
    "    region_size = 5000/32\n",
    "    region_spacing = 3000/32\n",
    "#     for cx in range(region_size/2, img.shape[1]-region_size/2+1, region_spacing):\n",
    "#         for cy in range(region_size/2, img.shape[0]-region_size/2+1, region_spacing):\n",
    "    for cx in range(0, img.shape[1], region_spacing):\n",
    "        for cy in range(0, img.shape[0], region_spacing):\n",
    "            region = img[max(cy-region_size/2, 0):min(cy+region_size/2+1, img.shape[0]-1), \n",
    "                         max(cx-region_size/2, 0):min(cx+region_size/2+1, img.shape[1]-1)]\n",
    "#             region_mask = raw_mask[max(cy-region_size/2, 0):min(cy+region_size/2+1, img.shape[0]-1), \n",
    "#                                    max(cx-region_size/2, 0):min(cx+region_size/2+1, img.shape[1]-1)]\n",
    "            region_mask = tb_mask[max(cy-region_size/2, 0):min(cy+region_size/2+1, img.shape[0]-1), \n",
    "                                   max(cx-region_size/2, 0):min(cx+region_size/2+1, img.shape[1]-1)]\n",
    "            if np.count_nonzero(region_mask) == 0:\n",
    "                continue\n",
    "            mean_std_all_regions.append((region[region_mask].mean(), region[region_mask].std()))\n",
    "            cx_cy_all_regions.append((cx, cy))\n",
    "            \n",
    "    sys.stderr.write('Compute mean/std for sample regions: %.2f seconds.\\n' % (time.time() - t))\n",
    "    \n",
    "    t = time.time()\n",
    "    mean_map = resample_scoremap(sparse_scores=np.array(mean_std_all_regions)[:,0], \n",
    "                             sample_locations=cx_cy_all_regions,\n",
    "                             gridspec=(region_size, region_spacing, img.shape[1], img.shape[0], (0,0)),\n",
    "                            downscale=4, \n",
    "                                 interpolation_order=2)\n",
    "\n",
    "    sys.stderr.write('Interpolate mean map: %.2f seconds.\\n' % (time.time() - t)) #10s\n",
    "\n",
    "    t = time.time()\n",
    "    mean_map = rescale_by_resampling(mean_map, new_shape=(img.shape[1], img.shape[0]))\n",
    "    sys.stderr.write('Scale up mean map: %.2f seconds.\\n' % (time.time() - t)) #30s\n",
    "\n",
    "    t = time.time()\n",
    "    std_map = resample_scoremap(sparse_scores=np.array(mean_std_all_regions)[:,1], \n",
    "                             sample_locations=cx_cy_all_regions,\n",
    "                             gridspec=(region_size, region_spacing, img.shape[1], img.shape[0], (0,0)),\n",
    "                            downscale=4,\n",
    "                               interpolation_order=2)\n",
    "    sys.stderr.write('Interpolate std map: %.2f seconds.\\n' % (time.time() - t)) #10s\n",
    "\n",
    "    t = time.time()\n",
    "    std_map = rescale_by_resampling(std_map, new_shape=(img.shape[1], img.shape[0]))\n",
    "    sys.stderr.write('Scale up std map: %.2f seconds.\\n' % (time.time() - t)) #30s\n",
    "    \n",
    "#     # Save mean/std results.\n",
    "    \n",
    "#     fp = DataManager.get_intensity_normalization_result_filepath(what='region_centers', stack=stack, section=section)\n",
    "#     create_parent_dir_if_not_exists(fp)    \n",
    "#     np.savetxt(fp, cx_cy_all_regions)\n",
    "    \n",
    "#     fp = DataManager.get_intensity_normalization_result_filepath(what='mean_std_all_regions', stack=stack, section=section)\n",
    "#     create_parent_dir_if_not_exists(fp)\n",
    "#     np.savetxt(fp, mean_std_all_regions)\n",
    "    \n",
    "#     fp = DataManager.get_intensity_normalization_result_filepath(what='mean_map', stack=stack, section=section)\n",
    "#     create_parent_dir_if_not_exists(fp)\n",
    "#     bp.pack_ndarray_file(mean_map.astype(np.float16), fp)\n",
    "    \n",
    "#     fp = DataManager.get_intensity_normalization_result_filepath(what='std_map', stack=stack, section=section)\n",
    "#     create_parent_dir_if_not_exists(fp)\n",
    "#     bp.pack_ndarray_file(std_map.astype(np.float16), fp)\n",
    "\n",
    "    # Export normalized image.\n",
    "    \n",
    "    t = time.time()\n",
    "#     raw_mask = raw_mask & (std_map > 0)\n",
    "#     img_normalized = np.zeros(img.shape, np.float32)\n",
    "#     img_normalized[raw_mask] = (img[raw_mask] - mean_map[raw_mask]) / std_map[raw_mask]\n",
    "    tb_mask = tb_mask & (std_map > 0)\n",
    "    img_normalized = np.zeros(img.shape, np.float32)\n",
    "    img_normalized[tb_mask] = (img[tb_mask] - mean_map[tb_mask]) / std_map[tb_mask]\n",
    "    sys.stderr.write('Normalize: %.2f seconds.\\n' % (time.time() - t)) #30s\n",
    "\n",
    "#     t = time.time()\n",
    "#     # FIX THIS! THIS only save uint16, not float16. Need to save as bp instead.\n",
    "# #     img_fp = DataManager.get_image_filepath_v2(stack=stack, prep_id=None, version='NtbNormalizedFloat', resol='down8', section=section, )\n",
    "# #     create_parent_dir_if_not_exists(img_fp)\n",
    "# #     imsave(img_fp, img_normalized[::8, ::8].astype(np.float16))\n",
    "#     save_data(img_normalized.astype(np.float16), \n",
    "#               DataManager.get_intensity_normalization_result_filepath(what='normalized_float_map', stack=stack, section=section),\n",
    "#              upload_s3=False)\n",
    "#     sys.stderr.write('Save float version: %.2f seconds.\\n' % (time.time() - t)) #30s\n",
    "        \n",
    "# #     t = time.time()\n",
    "# #     img_normalized_uint8 = rescale_intensity_v2(img_normalized, -1, 6)\n",
    "# #     sys.stderr.write('Rescale to uint8: %.2f seconds.\\n' % (time.time() - t)) #30s\n",
    "    \n",
    "# #     t = time.time()\n",
    "# #     img_fp = DataManager.get_image_filepath_v2(stack=stack, prep_id=None, version='NtbNormalized', resol='raw', section=section)\n",
    "# #     create_parent_dir_if_not_exists(img_fp)\n",
    "# #     imsave(img_fp, img_normalized_uint8)\n",
    "# #     sys.stderr.write('Save uint8 version: %.2f seconds.\\n' % (time.time() - t)) #30s\n",
    "    \n",
    "#     # Export histogram.\n",
    "    \n",
    "#     plt.hist(img_normalized[raw_mask].flatten(), bins=100, log=True);\n",
    "#     fp = DataManager.get_intensity_normalization_result_filepath(what='float_histogram_png', stack=stack, section=section)\n",
    "#     create_parent_dir_if_not_exists(fp)\n",
    "#     plt.savefig(fp)\n",
    "#     plt.close();\n",
    "    \n",
    "# #     hist_fp = DataManager.get_intensity_normalization_result_filepath(what='float_histogram', stack=stack, section=section)\n",
    "# #     create_parent_dir_if_not_exists(hist_fp)\n",
    "    \n",
    "# #     hist, bin_edges = np.histogram(img_normalized[valid_mask].flatten(), bins=np.arange(0,201,5));\n",
    "\n",
    "# #     plt.bar(bin_edges[:-1], np.log(hist));\n",
    "# #     plt.xticks(np.arange(0, 200, 20), np.arange(0, 200, 20));\n",
    "# #     plt.xlabel('Normalized pixel value (float)');\n",
    "# #     plt.title(metadata_cache['sections_to_filenames'][stack][section])\n",
    "\n",
    "# #     plt.savefig(hist_fp)\n",
    "# #     plt.close();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(694, 1372)"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "std_map.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trying to load /data/CSHL_data_processed/DEMO999/DEMO999_raw_Ntb/MD662&661-F102-2017.06.06-22.30.50_MD661_2_0305_raw_Ntb.tif\n",
      "Load image: 2.36 seconds.\n",
      "/usr/local/lib/python2.7/dist-packages/skimage/transform/_warps.py:84: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n",
      "Rescale mask: 29.54 seconds.\n",
      "Compute mean/std for sample regions: 11.36 seconds.\n",
      "Interpolate mean map: 7.11 seconds.\n",
      "Scale up mean map: 18.18 seconds.\n",
      "Interpolate std map: 7.18 seconds.\n",
      "Scale up std map: 17.64 seconds.\n",
      "Normalize: 10.94 seconds.\n",
      "Save float version: 9.09 seconds.\n",
      "Trying to load /data/CSHL_data_processed/DEMO999/DEMO999_raw_Ntb/MD662&661-F102-2017.06.06-22.30.50_MD661_1_0304_raw_Ntb.tif\n",
      "Load image: 2.77 seconds.\n",
      "Rescale mask: 31.94 seconds.\n",
      "Compute mean/std for sample regions: 11.84 seconds.\n",
      "Interpolate mean map: 8.51 seconds.\n",
      "Scale up mean map: 18.46 seconds.\n",
      "Interpolate std map: 8.59 seconds.\n",
      "Scale up std map: 17.85 seconds.\n",
      "Normalize: 13.43 seconds.\n",
      "Save float version: 9.38 seconds.\n",
      "Trying to load /data/CSHL_data_processed/DEMO999/DEMO999_raw_Ntb/MD662&661-F101-2017.06.06-22.05.45_MD661_2_0302_raw_Ntb.tif\n",
      "Load image: 15.79 seconds.\n",
      "Rescale mask: 30.83 seconds.\n",
      "Compute mean/std for sample regions: 12.28 seconds.\n",
      "Interpolate mean map: 8.23 seconds.\n",
      "Scale up mean map: 18.04 seconds.\n",
      "Interpolate std map: 8.02 seconds.\n",
      "Scale up std map: 17.25 seconds.\n",
      "Normalize: 14.29 seconds.\n",
      "Save float version: 8.70 seconds.\n",
      "Trying to load /data/CSHL_data_processed/DEMO999/DEMO999_raw_Ntb/MD662&661-F101-2017.06.06-22.05.45_MD661_1_0301_raw_Ntb.tif\n",
      "Load image: 2.71 seconds.\n",
      "Rescale mask: 31.83 seconds.\n",
      "Compute mean/std for sample regions: 11.28 seconds.\n",
      "Interpolate mean map: 7.77 seconds.\n",
      "Scale up mean map: 16.94 seconds.\n",
      "Interpolate std map: 7.63 seconds.\n",
      "Scale up std map: 16.15 seconds.\n",
      "Normalize: 12.35 seconds.\n",
      "Save float version: 8.58 seconds.\n"
     ]
    }
   ],
   "source": [
    "# for section in set(metadata_cache['valid_sections_all'][stack]) - set(metadata_cache['valid_sections'][stack]):\n",
    "# for section in metadata_cache['valid_sections'][stack]:\n",
    "\n",
    "for image_name in all_image_names:\n",
    "\n",
    "#     print \"Section\", section\n",
    "    \n",
    "    t = time.time()\n",
    "    \n",
    "    img = DataManager.load_image_v2(stack=stack, prep_id=prep_id, fn=image_name, version=version, resol=resol)\n",
    "\n",
    "    sys.stderr.write('Load image: %.2f seconds.\\n' % (time.time() - t))\n",
    "\n",
    "    t = time.time()\n",
    "    tb_mask = DataManager.load_thumbnail_mask_v3(stack=stack, prep_id=None, fn=image_name)\n",
    "#     raw_mask = rescale_by_resampling(tb_mask, new_shape=(img.shape[1], img.shape[0]))\n",
    "    raw_mask = resize(tb_mask, img.shape) > .5\n",
    "    \n",
    "    save_data(raw_mask, \n",
    "          DataManager.get_image_filepath_v2(stack=stack, prep_id=prep_id, fn=image_name, version='mask', resol=resol, ext='bp'), \n",
    "          upload_s3=False)\n",
    "    \n",
    "    sys.stderr.write('Rescale mask: %.2f seconds.\\n' % (time.time() - t))\n",
    "\n",
    "    t = time.time()\n",
    "    \n",
    "    mean_std_all_regions = []\n",
    "    cx_cy_all_regions = []\n",
    "    region_size = 5000\n",
    "    region_spacing = 3000\n",
    "#     for cx in range(region_size/2, img.shape[1]-region_size/2+1, region_spacing):\n",
    "#         for cy in range(region_size/2, img.shape[0]-region_size/2+1, region_spacing):\n",
    "    for cx in range(0, img.shape[1], region_spacing):\n",
    "        for cy in range(0, img.shape[0], region_spacing):\n",
    "            region = img[max(cy-region_size/2, 0):min(cy+region_size/2+1, img.shape[0]-1), \n",
    "                         max(cx-region_size/2, 0):min(cx+region_size/2+1, img.shape[1]-1)]\n",
    "            region_mask = raw_mask[max(cy-region_size/2, 0):min(cy+region_size/2+1, img.shape[0]-1), \n",
    "                                   max(cx-region_size/2, 0):min(cx+region_size/2+1, img.shape[1]-1)]\n",
    "            if np.count_nonzero(region_mask) == 0:\n",
    "                continue\n",
    "            mean_std_all_regions.append((region[region_mask].mean(), region[region_mask].std()))\n",
    "            cx_cy_all_regions.append((cx, cy))\n",
    "            \n",
    "    sys.stderr.write('Compute mean/std for sample regions: %.2f seconds.\\n' % (time.time() - t))\n",
    "    \n",
    "    t = time.time()\n",
    "    mean_map = resample_scoremap(sparse_scores=np.array(mean_std_all_regions)[:,0], \n",
    "                             sample_locations=cx_cy_all_regions,\n",
    "                             gridspec=(region_size, region_spacing, img.shape[1], img.shape[0], (0,0)),\n",
    "                            downscale=4, \n",
    "                                 interpolation_order=2)\n",
    "\n",
    "    sys.stderr.write('Interpolate mean map: %.2f seconds.\\n' % (time.time() - t)) #10s\n",
    "\n",
    "    t = time.time()\n",
    "    mean_map = rescale_by_resampling(mean_map, new_shape=(img.shape[1], img.shape[0]))\n",
    "    sys.stderr.write('Scale up mean map: %.2f seconds.\\n' % (time.time() - t)) #30s\n",
    "\n",
    "    t = time.time()\n",
    "    std_map = resample_scoremap(sparse_scores=np.array(mean_std_all_regions)[:,1], \n",
    "                             sample_locations=cx_cy_all_regions,\n",
    "                             gridspec=(region_size, region_spacing, img.shape[1], img.shape[0], (0,0)),\n",
    "                            downscale=4,\n",
    "                               interpolation_order=2)\n",
    "    sys.stderr.write('Interpolate std map: %.2f seconds.\\n' % (time.time() - t)) #10s\n",
    "\n",
    "    t = time.time()\n",
    "    std_map = rescale_by_resampling(std_map, new_shape=(img.shape[1], img.shape[0]))\n",
    "    sys.stderr.write('Scale up std map: %.2f seconds.\\n' % (time.time() - t)) #30s\n",
    "    \n",
    "    # Save mean/std results.\n",
    "    \n",
    "    fp = DataManager.get_intensity_normalization_result_filepath(what='region_centers', stack=stack, fn=image_name)\n",
    "    create_parent_dir_if_not_exists(fp)    \n",
    "    np.savetxt(fp, cx_cy_all_regions)\n",
    "    \n",
    "    fp = DataManager.get_intensity_normalization_result_filepath(what='mean_std_all_regions', stack=stack, fn=image_name)\n",
    "    create_parent_dir_if_not_exists(fp)\n",
    "    np.savetxt(fp, mean_std_all_regions)\n",
    "    \n",
    "    fp = DataManager.get_intensity_normalization_result_filepath(what='mean_map', stack=stack, fn=image_name)\n",
    "    create_parent_dir_if_not_exists(fp)\n",
    "    bp.pack_ndarray_file(mean_map.astype(np.float16), fp)\n",
    "    \n",
    "    fp = DataManager.get_intensity_normalization_result_filepath(what='std_map', stack=stack, fn=image_name)\n",
    "    create_parent_dir_if_not_exists(fp)\n",
    "    bp.pack_ndarray_file(std_map.astype(np.float16), fp)\n",
    "\n",
    "    # Export normalized image.\n",
    "    \n",
    "    t = time.time()\n",
    "    raw_mask = raw_mask & (std_map > 0)\n",
    "    img_normalized = np.zeros(img.shape, np.float32)\n",
    "    img_normalized[raw_mask] = (img[raw_mask] - mean_map[raw_mask]) / std_map[raw_mask]\n",
    "    sys.stderr.write('Normalize: %.2f seconds.\\n' % (time.time() - t)) #30s\n",
    "\n",
    "    t = time.time()\n",
    "    # FIX THIS! THIS only save uint16, not float16. Need to save as bp instead.\n",
    "#     img_fp = DataManager.get_image_filepath_v2(stack=stack, prep_id=None, version='NtbNormalizedFloat', resol='down8', section=section, )\n",
    "#     create_parent_dir_if_not_exists(img_fp)\n",
    "#     imsave(img_fp, img_normalized[::8, ::8].astype(np.float16))\n",
    "    save_data(img_normalized.astype(np.float16), \n",
    "              DataManager.get_intensity_normalization_result_filepath(what='normalized_float_map', stack=stack, fn=image_name),\n",
    "             upload_s3=False)\n",
    "    sys.stderr.write('Save float version: %.2f seconds.\\n' % (time.time() - t)) #30s\n",
    "        \n",
    "#     t = time.time()\n",
    "#     img_normalized_uint8 = rescale_intensity_v2(img_normalized, -1, 6)\n",
    "#     sys.stderr.write('Rescale to uint8: %.2f seconds.\\n' % (time.time() - t)) #30s\n",
    "    \n",
    "#     t = time.time()\n",
    "#     img_fp = DataManager.get_image_filepath_v2(stack=stack, prep_id=None, version='NtbNormalized', resol='raw', section=section)\n",
    "#     create_parent_dir_if_not_exists(img_fp)\n",
    "#     imsave(img_fp, img_normalized_uint8)\n",
    "#     sys.stderr.write('Save uint8 version: %.2f seconds.\\n' % (time.time() - t)) #30s\n",
    "    \n",
    "    # Export histogram.\n",
    "    \n",
    "    plt.hist(img_normalized[raw_mask].flatten(), bins=100, log=True);\n",
    "    fp = DataManager.get_intensity_normalization_result_filepath(what='float_histogram_png', stack=stack, fn=image_name)\n",
    "    create_parent_dir_if_not_exists(fp)\n",
    "    plt.savefig(fp)\n",
    "    plt.close();\n",
    "    \n",
    "#     hist_fp = DataManager.get_intensity_normalization_result_filepath(what='float_histogram', stack=stack, section=section)\n",
    "#     create_parent_dir_if_not_exists(hist_fp)\n",
    "    \n",
    "#     hist, bin_edges = np.histogram(img_normalized[valid_mask].flatten(), bins=np.arange(0,201,5));\n",
    "\n",
    "#     plt.bar(bin_edges[:-1], np.log(hist));\n",
    "#     plt.xticks(np.arange(0, 200, 20), np.arange(0, 200, 20));\n",
    "#     plt.xlabel('Normalized pixel value (float)');\n",
    "#     plt.title(metadata_cache['sections_to_filenames'][stack][section])\n",
    "\n",
    "#     plt.savefig(hist_fp)\n",
    "#     plt.close();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/skimage/util/dtype.py:122: UserWarning: Possible precision loss when converting from float64 to uint8\n",
      "  .format(dtypeobj_in, dtypeobj_out))\n"
     ]
    }
   ],
   "source": [
    "gamma_map = img_as_ubyte(adjust_gamma(np.arange(0, 256, 1) / 255., 8.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "low = -2.\n",
    "high = 50."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rescale to uint8: 35.48 seconds.\n",
      "Load mask: 1.72 seconds.\n",
      "Rescale to uint8: 41.11 seconds.\n",
      "Load mask: 2.36 seconds.\n",
      "Rescale to uint8: 27.04 seconds.\n",
      "Load mask: 1.65 seconds.\n",
      "Rescale to uint8: 29.19 seconds.\n",
      "Load mask: 1.71 seconds.\n"
     ]
    }
   ],
   "source": [
    "for image_name in all_image_names:\n",
    "\n",
    "    img_normalized = load_data(\n",
    "              DataManager.get_intensity_normalization_result_filepath(what='normalized_float_map', stack=stack, fn=image_name),\n",
    "             download_s3=False)    \n",
    "    \n",
    "    t = time.time()\n",
    "    img_normalized_uint8 = rescale_intensity_v2(img_normalized, low, high)\n",
    "    sys.stderr.write('Rescale to uint8: %.2f seconds.\\n' % (time.time() - t))\n",
    "\n",
    "    t = time.time()\n",
    "    raw_mask = load_data(DataManager.get_image_filepath_v2(stack=stack, prep_id=prep_id, fn=image_name, version='mask', resol=resol, ext='bp'),\n",
    "                        download_s3=False)\n",
    "    img_normalized_uint8[~raw_mask] = 0\n",
    "    sys.stderr.write('Load mask: %.2f seconds.\\n' % (time.time() - t))\n",
    "        \n",
    "    img = 255 - img_normalized_uint8\n",
    "    save_data(gamma_map[img], \n",
    "              DataManager.get_image_filepath_v2(stack=stack, prep_id=prep_id, fn=image_name, version=out_version, resol=resol),\n",
    "             upload_s3=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# (HUMAN) Give alignedWithMargin cropbox, based on alignedPadded images.\n",
    "# or automatically infer based on alignedPadded masks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_name_list = ['MD662&661-F101-2017.06.06-22.05.45_MD661_1_0301',\n",
    "        'MD662&661-F101-2017.06.06-22.05.45_MD661_2_0302',\n",
    "        'MD662&661-F102-2017.06.06-22.30.50_MD661_1_0304',\n",
    "        'MD662&661-F102-2017.06.06-22.30.50_MD661_2_0305'\n",
    "                  ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ventral_limit': 645, 'caudal_limit': 1223, 'resolution': 'down32', 'wrt': 'alignedPadded', 'dorsal_limit': 55, 'rostral_limit': 10}\n"
     ]
    }
   ],
   "source": [
    "resol = 'down32'\n",
    "\n",
    "bbox_all_images = []\n",
    "for img_name in image_name_list:\n",
    "    mask_tb_alignedPadded = DataManager.load_thumbnail_mask_v3(stack=stack, prep_id='alignedPadded', fn=img_name)\n",
    "    bbox = bbox_2d(mask_tb_alignedPadded)\n",
    "    bbox_all_images.append(bbox)\n",
    "bbox_all_images = np.array(bbox_all_images)\n",
    "\n",
    "#     bbox_all_images = np.array([\n",
    "#         bbox_2d(DataManager.load_thumbnail_mask_v3(stack=stack, prep_id=1, fn=fn))\n",
    "#         for fn in metadata_cache['valid_filenames'][stack]\n",
    "#     ])\n",
    "\n",
    "# Are the bounding boxes reasonable? If some numbers stand out, go back to check the mask.\n",
    "# plt.figure(figsize=(10,5));\n",
    "# plt.plot(bbox_all_images[:,0], label='xmin')\n",
    "# plt.plot(bbox_all_images[:,1], label='xmax')\n",
    "# plt.plot(bbox_all_images[:,2], label='ymin')\n",
    "# plt.plot(bbox_all_images[:,3], label='ymax')\n",
    "# plt.legend();\n",
    "# plt.show();\n",
    "\n",
    "margin_um = 736\n",
    "margin = int(np.round(margin_um / convert_resolution_string_to_um(resolution=resol, stack=stack)))\n",
    "alignedWithMargin_xmin, alignedWithMargin_ymin = np.maximum(bbox_all_images[:, [0,2]].min(axis=0) - margin, 0)\n",
    "alignedWithMargin_xmax, alignedWithMargin_ymax = np.minimum(bbox_all_images[:, [1,3]].max(axis=0) + margin, \n",
    "                                                            [mask_tb_alignedPadded.shape[1]-1, mask_tb_alignedPadded.shape[0]-1])\n",
    "\n",
    "# print alignedWithMargin_xmin, alignedWithMargin_xmax, alignedWithMargin_ymin, alignedWithMargin_ymax \n",
    "\n",
    "alignedWithMargin_cropbox = {'rostral_limit': alignedWithMargin_xmin, 'caudal_limit': alignedWithMargin_xmax, \n",
    "'dorsal_limit': alignedWithMargin_ymin, 'ventral_limit': alignedWithMargin_ymax,\n",
    "                            'resolution': resol, 'wrt': 'alignedPadded'}\n",
    "\n",
    "print alignedWithMargin_cropbox\n",
    "\n",
    "save_data(alignedWithMargin_cropbox, \n",
    "          DataManager.get_cropbox_filename_v2(stack=stack, anchor_fn=None, prep_id='alignedWithMargin'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for img_name in image_name_list:\n",
    "#     mask_tb_alignedPadded = DataManager.load_thumbnail_mask_v3(stack=stack, prep_id='alignedPadded', fn=img_name)\n",
    "#     plt.figure();\n",
    "#     plt.imshow(mask_tb_alignedPadded[alignedWithMargin_ymin:alignedWithMargin_ymax+1, \n",
    "#                                      alignedWithMargin_xmin:alignedWithMargin_xmax+1], cmap=plt.cm.gray)\n",
    "#     plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# thumbnail -> prep1_thumbnail + prep1_thumbnail -> prep5_thumbnail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting input_spec.ini\n"
     ]
    }
   ],
   "source": [
    "%%writefile input_spec.ini\n",
    "[DEFAULT]\n",
    "image_name_list = MD662&661-F101-2017.06.06-22.05.45_MD661_1_0301\n",
    "        MD662&661-F101-2017.06.06-22.05.45_MD661_2_0302\n",
    "        MD662&661-F102-2017.06.06-22.30.50_MD661_1_0304\n",
    "        MD662&661-F102-2017.06.06-22.30.50_MD661_2_0305\n",
    "stack = DEMO998\n",
    "prep_id = None\n",
    "version = NtbNormalizedAdaptiveInvertedGamma\n",
    "resol = thumbnail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ENABLE_UPLOAD_S3 is not set, default to False.\n",
      "ENABLE_DOWNLOAD_S3 is not set, default to False.\n",
      "Setting environment for Precision WorkStation\n",
      "No vtk\n",
      "File does not exist: /data/CSHL_data_processed/DEMO999/DEMO999_anchor.txt\n",
      "File does not exist: /data/CSHL_data_processed/DEMO999/DEMO999_sorted_filenames.txt\n",
      "File does not exist: /data/CSHL_data_processed/DEMO999/DEMO999_sorted_filenames.txt\n",
      "File does not exist: /data/CSHL_data_processed/DEMO999/DEMO999_anchor.txt\n",
      "File does not exist: /data/CSHL_data_processed/DEMO999/DEMO999_anchor.txt\n",
      "File does not exist: /data/CSHL_data_processed/DEMO999/DEMO999_anchor.txt\n",
      "rm -f /tmp/stderr_*; rm -f /tmp/stdout_*\n",
      "return code: 0\n",
      "Run locally.\n",
      "Jobs submitted. Use wait_qsub_complete() to wait for all execution to finish.\n"
     ]
    }
   ],
   "source": [
    "! python warp_crop.py --input_spec input_spec.ini \\\n",
    " --warp \"{toanchor_transforms_fp}\" \\\n",
    " --crop \"{DataManager.get_cropbox_filename_v2(stack=stack, anchor_fn=None, prep_id='alignedWithMargin')}\" \\\n",
    " --out_prep_id alignedWithMargin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# raw -> prep1_raw + prep1_raw -> prep5_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting input_spec.ini\n"
     ]
    }
   ],
   "source": [
    "%%writefile input_spec.ini\n",
    "[DEFAULT]\n",
    "image_name_list = MD662&661-F101-2017.06.06-22.05.45_MD661_1_0301\n",
    "        MD662&661-F101-2017.06.06-22.05.45_MD661_2_0302\n",
    "        MD662&661-F102-2017.06.06-22.30.50_MD661_1_0304\n",
    "        MD662&661-F102-2017.06.06-22.30.50_MD661_2_0305\n",
    "stack = DEMO998\n",
    "prep_id = None\n",
    "version = NtbNormalizedAdaptiveInvertedGamma\n",
    "resol = raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ENABLE_UPLOAD_S3 is not set, default to False.\n",
      "ENABLE_DOWNLOAD_S3 is not set, default to False.\n",
      "Setting environment for Precision WorkStation\n",
      "No vtk\n",
      "File does not exist: /data/CSHL_data_processed/DEMO999/DEMO999_anchor.txt\n",
      "File does not exist: /data/CSHL_data_processed/DEMO999/DEMO999_sorted_filenames.txt\n",
      "File does not exist: /data/CSHL_data_processed/DEMO999/DEMO999_sorted_filenames.txt\n",
      "File does not exist: /data/CSHL_data_processed/DEMO999/DEMO999_anchor.txt\n",
      "File does not exist: /data/CSHL_data_processed/DEMO999/DEMO999_anchor.txt\n",
      "File does not exist: /data/CSHL_data_processed/DEMO999/DEMO999_anchor.txt\n",
      "rm -f /tmp/stderr_*; rm -f /tmp/stdout_*\n",
      "return code: 0\n",
      "Run locally.\n",
      "Jobs submitted. Use wait_qsub_complete() to wait for all execution to finish.\n"
     ]
    }
   ],
   "source": [
    "! python warp_crop.py --input_spec input_spec.ini \\\n",
    " --warp \"{toanchor_transforms_fp}\" \\\n",
    " --crop \"{DataManager.get_cropbox_filename_v2(stack=stack, anchor_fn=None, prep_id='alignedWithMargin')}\" \\\n",
    " --out_prep_id alignedWithMargin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# prep5_raw_NtbNormalizedAdaptiveInvertedGamma -> prep5_thumbnail_NtbNormalizedAdaptiveInvertedGamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting input_spec.ini\n"
     ]
    }
   ],
   "source": [
    "%%writefile input_spec.ini\n",
    "[DEFAULT]\n",
    "image_name_list = MD662&661-F101-2017.06.06-22.05.45_MD661_1_0301\n",
    "        MD662&661-F101-2017.06.06-22.05.45_MD661_2_0302\n",
    "        MD662&661-F102-2017.06.06-22.30.50_MD661_1_0304\n",
    "        MD662&661-F102-2017.06.06-22.30.50_MD661_2_0305\n",
    "stack = DEMO998\n",
    "prep_id = alignedWithMargin\n",
    "version = NtbNormalizedAdaptiveInvertedGamma\n",
    "resol = raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ENABLE_UPLOAD_S3 is not set, default to False.\n",
      "ENABLE_DOWNLOAD_S3 is not set, default to False.\n",
      "Setting environment for Precision WorkStation\n",
      "No vtk\n",
      "File does not exist: /data/CSHL_data_processed/DEMO999/DEMO999_anchor.txt\n",
      "File does not exist: /data/CSHL_data_processed/DEMO999/DEMO999_sorted_filenames.txt\n",
      "File does not exist: /data/CSHL_data_processed/DEMO999/DEMO999_sorted_filenames.txt\n",
      "File does not exist: /data/CSHL_data_processed/DEMO999/DEMO999_anchor.txt\n",
      "File does not exist: /data/CSHL_data_processed/DEMO999/DEMO999_anchor.txt\n",
      "File does not exist: /data/CSHL_data_processed/DEMO999/DEMO999_anchor.txt\n",
      "/usr/local/lib/python2.7/dist-packages/skimage/external/tifffile/tifffile.py:2611: RuntimeWarning: py_decodelzw encountered unexpected end of stream\n",
      "  strip = decompress(strip)\n",
      "/data/CSHL_data_processed/DEMO998/DEMO998_prep5_raw_NtbNormalizedAdaptiveInvertedGamma/MD662&661-F101-2017.06.06-22.05.45_MD661_1_0301_prep5_raw_NtbNormalizedAdaptiveInvertedGamma.tif\n",
      "uint8\n",
      "Rescale: 6.54 seconds.\n",
      "/data/CSHL_data_processed/DEMO998/DEMO998_prep5_raw_NtbNormalizedAdaptiveInvertedGamma/MD662&661-F101-2017.06.06-22.05.45_MD661_2_0302_prep5_raw_NtbNormalizedAdaptiveInvertedGamma.tif\n",
      "uint8\n",
      "Rescale: 6.35 seconds.\n",
      "/data/CSHL_data_processed/DEMO998/DEMO998_prep5_raw_NtbNormalizedAdaptiveInvertedGamma/MD662&661-F102-2017.06.06-22.30.50_MD661_1_0304_prep5_raw_NtbNormalizedAdaptiveInvertedGamma.tif\n",
      "uint8\n",
      "Rescale: 6.21 seconds.\n",
      "/data/CSHL_data_processed/DEMO998/DEMO998_prep5_raw_NtbNormalizedAdaptiveInvertedGamma/MD662&661-F102-2017.06.06-22.30.50_MD661_2_0305_prep5_raw_NtbNormalizedAdaptiveInvertedGamma.tif\n",
      "uint8\n",
      "Rescale: 6.21 seconds.\n"
     ]
    }
   ],
   "source": [
    "! python rescale.py input_spec.ini thumbnail -f {1./32}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# **(HUMAN)** Specify prep2 (alignedBrainstemCrop) cropping box, based on alignedWithMargin thumbnails or alignedPadded thumbnails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting /data/CSHL_data_processed/DEMO998/DEMO998_alignedTo_MD662&661-F102-2017.06.06-22.30.50_MD661_1_0304_prep2_cropbox.json\n"
     ]
    }
   ],
   "source": [
    "%%writefile {DataManager.get_cropbox_filename_v2(stack=stack, prep_id='alignedBrainstemCrop')}\n",
    "{\"rostral_limit\": 419, \"caudal_limit\": 1148, \"dorsal_limit\": 128, \"ventral_limit\": 608, \"resolution\": \"down32\", \"wrt\": \"alignedPadded\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# prep5_raw_NtbNormalizedAdaptiveInvertedGamma -> prep2_raw_NtbNormalizedAdaptiveInvertedGamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting input_spec.ini\n"
     ]
    }
   ],
   "source": [
    "%%writefile input_spec.ini\n",
    "[DEFAULT]\n",
    "image_name_list = MD662&661-F101-2017.06.06-22.05.45_MD661_1_0301\n",
    "        MD662&661-F101-2017.06.06-22.05.45_MD661_2_0302\n",
    "        MD662&661-F102-2017.06.06-22.30.50_MD661_1_0304\n",
    "        MD662&661-F102-2017.06.06-22.30.50_MD661_2_0305\n",
    "stack = DEMO998\n",
    "prep_id = alignedWithMargin\n",
    "version = NtbNormalizedAdaptiveInvertedGamma\n",
    "resol = raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convert_cropbox_from_arr_xywh_1um(data, out_fmt, out_resol, stack=None):\n",
    "\n",
    "    data = data / convert_resolution_string_to_um(stack=stack, resolution=out_resol)\n",
    "\n",
    "    if out_fmt == 'str_xywh':\n",
    "        return ','.join(map(str, data))\n",
    "    elif out_fmt == 'dict':\n",
    "        raise Exception(\"too lazy to implement\")\n",
    "    else:\n",
    "        return data\n",
    "\n",
    "def convert_cropbox_to_arr_xywh_1um(data, in_fmt, in_resol, stack=None):\n",
    "\n",
    "    if isinstance(data, dict):\n",
    "        arr_xywh = np.array([data['rostral_limit'], data['dorsal_limit'], data['caudal_limit'] - data['rostral_limit'] + 1, data['ventral_limit'] - data['dorsal_limit'] + 1])\n",
    "        # Since this does not check for wrt, the user needs to make sure the cropbox is relative to the input prep (i.e. the wrt attribute is the same as input prep)\n",
    "    elif isinstance(data, str):\n",
    "        if in_fmt == 'str_xywh':\n",
    "            arr_xywh = np.array(map(int, map(eval, data.split(','))))\n",
    "        elif in_fmt == 'str_xxyy':\n",
    "            arr_xxyy = np.array(map(int, map(eval, data.split(','))))\n",
    "            arr_xywh = np.array([arr_xxyy[0], arr_xxyy[2], arr_xxyy[1] - arr_xxyy[0] + 1, arr_xxyy[3] - arr_xxyy[2] + 1])\n",
    "        else:\n",
    "            raise\n",
    "    else:\n",
    "        if in_fmt == 'arr_xywh':\n",
    "            arr_xywh = np.array(data)\n",
    "        elif in_fmt == 'arr_xxyy':\n",
    "            arr_xywh = np.array([data[0], data[2], data[1] - data[0] + 1, data[3] - data[2] + 1])\n",
    "        else:\n",
    "            raise\n",
    "            \n",
    "    arr_xywh_1um = arr_xywh * convert_resolution_string_to_um(stack=stack, resolution=in_resol)\n",
    "    return arr_xywh_1um\n",
    "\n",
    "def convert_cropbox_fmt(in_fmt, out_fmt, data, in_resol='1um', out_resol='1um', stack=None):\n",
    "    arr_xywh_1um = convert_cropbox_to_arr_xywh_1um(data=data, in_fmt=in_fmt, in_resol=in_resol, stack=stack)\n",
    "    return convert_cropbox_from_arr_xywh_1um(data=arr_xywh_1um, out_fmt=out_fmt, out_resol=out_resol, stack=stack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ENABLE_UPLOAD_S3 is not set, default to False.\n",
      "ENABLE_DOWNLOAD_S3 is not set, default to False.\n",
      "Setting environment for Precision WorkStation\n",
      "No vtk\n",
      "File does not exist: /data/CSHL_data_processed/DEMO999/DEMO999_anchor.txt\n",
      "File does not exist: /data/CSHL_data_processed/DEMO999/DEMO999_sorted_filenames.txt\n",
      "File does not exist: /data/CSHL_data_processed/DEMO999/DEMO999_sorted_filenames.txt\n",
      "File does not exist: /data/CSHL_data_processed/DEMO999/DEMO999_anchor.txt\n",
      "File does not exist: /data/CSHL_data_processed/DEMO999/DEMO999_anchor.txt\n",
      "File does not exist: /data/CSHL_data_processed/DEMO999/DEMO999_anchor.txt\n",
      "rm -f /tmp/stderr_*; rm -f /tmp/stdout_*\n",
      "return code: 0\n",
      "Run locally.\n",
      "Jobs submitted. Use wait_qsub_complete() to wait for all execution to finish.\n"
     ]
    }
   ],
   "source": [
    "! python warp_crop.py --input_spec input_spec.ini \\\n",
    " --warp \"{toanchor_transforms_fp}\" \\\n",
    " --crop \"{convert_cropbox_fmt(data=DataManager.load_cropbox_v2_relative(stack=stack, prep_id='alignedBrainstemCrop', \\\n",
    "                                     wrt_prep_id='alignedWithMargin', \\\n",
    "                                    out_resolution='thumbnail'), \\\n",
    "                    in_fmt='arr_xxyy', out_fmt='str_xywh', stack=stack)}\" \\\n",
    " --out_prep_id alignedBrainstemCrop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# prep2_raw_NtbNormalizedAdaptiveInvertedGamma -> prep2_raw_NtbNormalizedAdaptiveInvertedGammaJpeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ENABLE_UPLOAD_S3 is not set, default to False.\n",
      "ENABLE_DOWNLOAD_S3 is not set, default to False.\n",
      "Setting environment for Precision WorkStation\n",
      "No vtk\n",
      "File does not exist: /data/CSHL_data_processed/DEMO999/DEMO999_anchor.txt\n",
      "File does not exist: /data/CSHL_data_processed/DEMO999/DEMO999_sorted_filenames.txt\n",
      "File does not exist: /data/CSHL_data_processed/DEMO999/DEMO999_sorted_filenames.txt\n",
      "File does not exist: /data/CSHL_data_processed/DEMO999/DEMO999_anchor.txt\n",
      "File does not exist: /data/CSHL_data_processed/DEMO999/DEMO999_anchor.txt\n",
      "File does not exist: /data/CSHL_data_processed/DEMO999/DEMO999_anchor.txt\n",
      "usage: compress_jpeg.py [-h] [--depth DEPTH] [--quality QUALITY] input_spec\n",
      "\n",
      "Compress image as JPEG. The output version is the input version with \"Jpeg\" appended.\n",
      "\n",
      "positional arguments:\n",
      "  input_spec         Input specifier\n",
      "\n",
      "optional arguments:\n",
      "  -h, --help         show this help message and exit\n",
      "  --depth DEPTH      Image depth\n",
      "  --quality QUALITY  JPEG quality\n"
     ]
    }
   ],
   "source": [
    "! python compress_jpeg.py -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting input_spec.ini\n"
     ]
    }
   ],
   "source": [
    "%%writefile input_spec.ini\n",
    "[DEFAULT]\n",
    "image_name_list = MD662&661-F101-2017.06.06-22.05.45_MD661_1_0301\n",
    "        MD662&661-F101-2017.06.06-22.05.45_MD661_2_0302\n",
    "        MD662&661-F102-2017.06.06-22.30.50_MD661_1_0304\n",
    "        MD662&661-F102-2017.06.06-22.30.50_MD661_2_0305\n",
    "stack = DEMO998\n",
    "prep_id = alignedBrainstemCrop\n",
    "version = NtbNormalizedAdaptiveInvertedGamma\n",
    "resol = raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ENABLE_UPLOAD_S3 is not set, default to False.\n",
      "ENABLE_DOWNLOAD_S3 is not set, default to False.\n",
      "Setting environment for Precision WorkStation\n",
      "No vtk\n",
      "File does not exist: /data/CSHL_data_processed/DEMO999/DEMO999_anchor.txt\n",
      "File does not exist: /data/CSHL_data_processed/DEMO999/DEMO999_sorted_filenames.txt\n",
      "File does not exist: /data/CSHL_data_processed/DEMO999/DEMO999_sorted_filenames.txt\n",
      "File does not exist: /data/CSHL_data_processed/DEMO999/DEMO999_anchor.txt\n",
      "File does not exist: /data/CSHL_data_processed/DEMO999/DEMO999_anchor.txt\n",
      "File does not exist: /data/CSHL_data_processed/DEMO999/DEMO999_anchor.txt\n",
      "convert \"/data/CSHL_data_processed/DEMO998/DEMO998_prep2_raw_NtbNormalizedAdaptiveInvertedGamma/MD662&661-F101-2017.06.06-22.05.45_MD661_1_0301_prep2_raw_NtbNormalizedAdaptiveInvertedGamma.tif\" -depth 8 -format jpg -quality 80 \"/data/CSHL_data_processed/DEMO998/DEMO998_prep2_raw_NtbNormalizedAdaptiveInvertedGammaJpeg/MD662&661-F101-2017.06.06-22.05.45_MD661_1_0301_prep2_raw_NtbNormalizedAdaptiveInvertedGammaJpeg.jpg\"\n",
      "return code: 0\n",
      "convert \"/data/CSHL_data_processed/DEMO998/DEMO998_prep2_raw_NtbNormalizedAdaptiveInvertedGamma/MD662&661-F101-2017.06.06-22.05.45_MD661_2_0302_prep2_raw_NtbNormalizedAdaptiveInvertedGamma.tif\" -depth 8 -format jpg -quality 80 \"/data/CSHL_data_processed/DEMO998/DEMO998_prep2_raw_NtbNormalizedAdaptiveInvertedGammaJpeg/MD662&661-F101-2017.06.06-22.05.45_MD661_2_0302_prep2_raw_NtbNormalizedAdaptiveInvertedGammaJpeg.jpg\"\n",
      "return code: 0\n",
      "convert \"/data/CSHL_data_processed/DEMO998/DEMO998_prep2_raw_NtbNormalizedAdaptiveInvertedGamma/MD662&661-F102-2017.06.06-22.30.50_MD661_1_0304_prep2_raw_NtbNormalizedAdaptiveInvertedGamma.tif\" -depth 8 -format jpg -quality 80 \"/data/CSHL_data_processed/DEMO998/DEMO998_prep2_raw_NtbNormalizedAdaptiveInvertedGammaJpeg/MD662&661-F102-2017.06.06-22.30.50_MD661_1_0304_prep2_raw_NtbNormalizedAdaptiveInvertedGammaJpeg.jpg\"\n",
      "return code: 0\n",
      "convert \"/data/CSHL_data_processed/DEMO998/DEMO998_prep2_raw_NtbNormalizedAdaptiveInvertedGamma/MD662&661-F102-2017.06.06-22.30.50_MD661_2_0305_prep2_raw_NtbNormalizedAdaptiveInvertedGamma.tif\" -depth 8 -format jpg -quality 80 \"/data/CSHL_data_processed/DEMO998/DEMO998_prep2_raw_NtbNormalizedAdaptiveInvertedGammaJpeg/MD662&661-F102-2017.06.06-22.30.50_MD661_2_0305_prep2_raw_NtbNormalizedAdaptiveInvertedGammaJpeg.jpg\"\n",
      "return code: 0\n"
     ]
    }
   ],
   "source": [
    "! python compress_jpeg.py input_spec.ini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
