{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import xml.etree.ElementTree as ET\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import sys, os\n",
    "sys.path.append(os.path.join(os.environ['REPO_DIR'], 'utilities'))\n",
    "from utilities2015 import *\n",
    "\n",
    "from data_manager import *\n",
    "from metadata import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from annotation_utilities import *\n",
    "from registration_utilities import *\n",
    "from conversion import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "brain_annotation_file_map = \\\n",
    "{\n",
    "'LM30new': ROOT_DIR + '/lauren_data/LM30_new.xml',\n",
    "'LM86': ROOT_DIR + '/lauren_data/LM86_FINAL_3D_SNr.xml',\n",
    "'LM27': ROOT_DIR + '/lauren_data/LSC_LM27_3D_FINAL.xml',\n",
    "    \n",
    "'LM41': ROOT_DIR + '/lauren_data/LM41_Final.xml',\n",
    "'LM22': ROOT_DIR + '/lauren_data/LM22_FINAL.xml',\n",
    "'LM17': ROOT_DIR + '/lauren_data/CSC_LM17_3D_FINAL.xml',\n",
    "\n",
    "'LM42_LM37': ROOT_DIR + '/lauren_data/LM42_LM37_FINAL.xml',\n",
    "'LM37': ROOT_DIR + '/lauren_data/mSC_LM37_3D_FINAL.xml',\n",
    "'LM95': ROOT_DIR + '/lauren_data/mSC_LM95_FINAL.xml',    \n",
    "\n",
    "'LM38': ROOT_DIR + '/lauren_data/LM38_FINAL_FLIP_L.xml', # fixed orientation to be the same as others\n",
    "'LM32': ROOT_DIR + '/lauren_data/LM32_FINAL.xml',\n",
    "    \n",
    "'LM40new': ROOT_DIR + '/lauren_data/LM40_new.xml',\n",
    "'LM54': ROOT_DIR + '/lauren_data/DR_LM54_FINAL.xml',\n",
    "'LM94_LM96_LM25': ROOT_DIR + '/lauren_data/DR_LM94_96_25_MERGE_FINAL2.xml',\n",
    "    \n",
    "'LM46': ROOT_DIR + '/lauren_data/LM46_FINAL.xml',    \n",
    "'LM84': ROOT_DIR + '/lauren_data/LM84_FINAL.xml',\n",
    "    \n",
    "'LM31': ROOT_DIR + '/lauren_data/LM31_FINAL.xml',\n",
    "'LM48': ROOT_DIR + '/lauren_data/LM48_FINAL.xml',\n",
    "# 'LM51': ROOT_DIR + '/lauren_data/PPN_LM51_FINAL_NEW.xml',\n",
    "# 'LM45': ROOT_DIR + '/lauren_data/PPN_LM45_FINAL_NEW.xml',\n",
    "    \n",
    "# 'LM97_LM98': ROOT_DIR + '/lauren_data/VM_LM97_98_MERGE_FINAL_2.xml',\n",
    "    \n",
    "# 'LM72': ROOT_DIR + '/lauren_data/LM72_3D_SNrl_FINAL_scaled.xml',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LM27\n",
      "rm -rf \"/home/yuncong/lauren_data/LSC_LM27_3D_FINAL.xml\" && mkdir -p \"/home/yuncong/lauren_data\"\n",
      "0\n",
      "aws s3 cp \"s3://mousebrainatlas-data/lauren_data/LSC_LM27_3D_FINAL.xml\" \"/home/yuncong/lauren_data/LSC_LM27_3D_FINAL.xml\"\n",
      "1\n"
     ]
    },
    {
     "ename": "IOError",
     "evalue": "[Errno 2] No such file or directory: '/home/yuncong//lauren_data/LSC_LM27_3D_FINAL.xml'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIOError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-f61078c5ef8c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mdownload_from_s3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxmlfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mtree\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mET\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxmlfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mroot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetroot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python2.7/xml/etree/ElementTree.pyc\u001b[0m in \u001b[0;36mparse\u001b[0;34m(source, parser)\u001b[0m\n\u001b[1;32m   1180\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1181\u001b[0m     \u001b[0mtree\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mElementTree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1182\u001b[0;31m     \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1183\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtree\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python2.7/xml/etree/ElementTree.pyc\u001b[0m in \u001b[0;36mparse\u001b[0;34m(self, source, parser)\u001b[0m\n\u001b[1;32m    645\u001b[0m         \u001b[0mclose_source\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    646\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"read\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 647\u001b[0;31m             \u001b[0msource\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    648\u001b[0m             \u001b[0mclose_source\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    649\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIOError\u001b[0m: [Errno 2] No such file or directory: '/home/yuncong//lauren_data/LSC_LM27_3D_FINAL.xml'"
     ]
    }
   ],
   "source": [
    "# for brain_name in brain_annotation_file_map.keys():\n",
    "for brain_name in ['LM38']:\n",
    "    \n",
    "    print brain_name\n",
    "\n",
    "    xmlfile = brain_annotation_file_map[brain_name]\n",
    "    download_from_s3(xmlfile)\n",
    "\n",
    "    tree = ET.parse(xmlfile)\n",
    "    root = tree.getroot()\n",
    "\n",
    "    neurolucida_name_map = \\\n",
    "    {\"Contour Name 1\": 'RMC_L',\n",
    "    \"Contour Name 2\": '3N_L',\n",
    "    # \"Contour Name 3\": 'fr',\n",
    "    'Brain': 'outline',\n",
    "     'Brain Outline': 'outline',\n",
    "     '3N': '3N_L',\n",
    "     'RN': 'RMC_L',\n",
    "     'RedNuc': 'RMC_L',\n",
    "     'SNR': 'SNR_L'}\n",
    "\n",
    "    prefix = '{http://www.mbfbioscience.com/2007/neurolucida}'\n",
    "\n",
    "    contours = defaultdict(list)\n",
    "\n",
    "    # Contour and marker coordinates are in um already.\n",
    "\n",
    "    for item in root.findall(prefix+'contour'):\n",
    "        name = item.attrib['name']\n",
    "        if name not in neurolucida_name_map:\n",
    "    #         raise Exception('Name %s in stack %s not recognized' % (name, stack))\n",
    "            sys.stderr.write('Name %s in stack %s not recognized. Ignored.\\n' % (name, brain_name))\n",
    "            continue\n",
    "        name = neurolucida_name_map[name]\n",
    "        curr_contour = []\n",
    "    #     try:\n",
    "    #         resolution = float(item.findall(prefix+'resolution')[0].text)\n",
    "    #         print resolution\n",
    "    #     except:\n",
    "    #         pass\n",
    "        for p in item.findall(prefix+'point'):\n",
    "            curr_contour.append((float(p.attrib['x']), float(p.attrib['y']), float(p.attrib['z'])))\n",
    "        contours[name].append(np.array(curr_contour))\n",
    "\n",
    "    contours.default_factory = None\n",
    "\n",
    "    markers = {}\n",
    "    # name = 'SNR'\n",
    "    name = 'All'\n",
    "\n",
    "    for item in root.findall(prefix+'marker'):\n",
    "        curr_markers = []\n",
    "        for p in item.findall(prefix+'point'):\n",
    "            curr_markers.append((float(p.attrib['x']), float(p.attrib['y']), float(p.attrib['z'])))\n",
    "        markers[name] = np.array(curr_markers)\n",
    "\n",
    "    contour_colors = dict(zip(contours.keys(), np.array(random_colors(len(contours)))/255.))\n",
    "    marker_colors = dict(zip(markers.keys(), np.array(random_colors(len(markers)))/255.))\n",
    "\n",
    "\n",
    "    # plt.figure(figsize=(10, 10));\n",
    "\n",
    "    # for name, cnts in contours.iteritems():    \n",
    "    # #     print name\n",
    "    # #     if parse_label(name)[1] == 'L' and \\\n",
    "    # #     (parse_label(name)[0] == '5N' or parse_label(name)[0] == '7N'  or parse_label(name)[0] == '7n' or parse_label(name)[0] == 'Sp5C'):\n",
    "    # #     if parse_label(name)[0] == '7N':\n",
    "    #     for cnt in cnts:\n",
    "    #         plt.plot(cnt[:, 2], cnt[:, 1], c=contour_colors[name]);\n",
    "    # plt.axis('equal');\n",
    "    # plt.xlabel('x');\n",
    "    # plt.ylabel('z');\n",
    "\n",
    "    ##############################\n",
    "\n",
    "    plt.figure(figsize=(10, 10));\n",
    "    for name, cnts in contours.iteritems():    \n",
    "    #     if parse_label(name)[1] == 'L' and \\\n",
    "    #     (parse_label(name)[0] == '5N' or parse_label(name)[0] == '7N'  or parse_label(name)[0] == '7n' or parse_label(name)[0] == 'Sp5C'):\n",
    "    #     if parse_label(name)[0] == '7N':\n",
    "        for cnt in cnts:\n",
    "            plt.plot(cnt[:, 0], cnt[:, 1], c=contour_colors[name]);\n",
    "\n",
    "    # plt.scatter(markers['SNR'][:,0], markers['SNR'][:,1], s=20, marker='*')\n",
    "    plt.scatter(markers['All'][:,0], markers['All'][:,1], s=20, marker='*')\n",
    "\n",
    "    # for name, mkrs in markers.iteritems():\n",
    "    #     plt.scatter(mkrs[:, 0], mkrs[:, 1], c=marker_colors[name], s=1, zorder=9);\n",
    "\n",
    "    plt.xlabel('x');\n",
    "    plt.ylabel('y');\n",
    "    plt.axis('equal');\n",
    "    # plt.legend();\n",
    "\n",
    "    ##############################\n",
    "\n",
    "    plt.figure(figsize=(10, 10));\n",
    "    for name, cnts in contours.iteritems():    \n",
    "    #     if parse_label(name)[1] == 'L' and \\\n",
    "    #     (parse_label(name)[0] == '5N' or parse_label(name)[0] == '7N'  or parse_label(name)[0] == '7n' or parse_label(name)[0] == 'Sp5C'):\n",
    "    #     if parse_label(name)[0] == '7N':\n",
    "        if name == 'SNR_L':\n",
    "            for cnt in cnts:\n",
    "                plt.plot(cnt[:, 2], cnt[:, 1], c=contour_colors[name]);\n",
    "\n",
    "    plt.scatter(markers['All'][:,2], markers['All'][:,1], s=20, marker='*')\n",
    "\n",
    "    # for name, mkrs in markers.iteritems():\n",
    "    #     plt.scatter(mkrs[:, 0], mkrs[:, 1], c=marker_colors[name], s=1, zorder=9);\n",
    "\n",
    "    plt.xlabel('x');\n",
    "    plt.ylabel('y');\n",
    "    plt.axis('equal');\n",
    "    # plt.legend();\n",
    "\n",
    "\n",
    "    structure_subset = \\\n",
    "    [name for name in contours.keys() if parse_label(name)[0] in all_known_structures]\n",
    "    print structure_subset\n",
    "\n",
    "    out_resolution = '10.0um'\n",
    "    out_resolution_um = convert_resolution_string_to_um(resolution=out_resolution)\n",
    "\n",
    "    # Lauren's data; coronal; \n",
    "    # x=left to right; y= superior to inferior (wrong! should be inferior to superior); z= anterior to posterior (they are coronal sections).\n",
    "\n",
    "    markers_orientationCorrected = {name_u: mkrs3d[:, [2,1,0]]*[1,-1,1] for name_u, mkrs3d in markers.iteritems()}\n",
    "    markers_atlasResol = {name: mkrs3d / out_resolution_um for name, mkrs3d in markers_orientationCorrected.iteritems()}\n",
    "\n",
    "    contours_orientationCorrected = {convert_to_left_name(name_u): [cnt[:, [2,1,0]]*[1,-1,1]\n",
    "                                     for cnt in cnts3d] \n",
    "                           for name_u, cnts3d in contours.iteritems()}\n",
    "\n",
    "    contours_atlasResol = {name: [cnt / out_resolution_um\n",
    "                                    for cnt in cnts3d if len(cnt) > 3] \n",
    "                           for name, cnts3d in contours_orientationCorrected.iteritems()}\n",
    "    #                                             if name in structure_subset}\n",
    "\n",
    "\n",
    "    # Convert contours to volumes\n",
    "\n",
    "    valid_level = .5\n",
    "\n",
    "    surround_distance_um = 200.\n",
    "    surround_distance_voxel = surround_distance_um / out_resolution_um\n",
    "    print \"surround size (in voxels):\", surround_distance_voxel\n",
    "\n",
    "    # Reconstruct brain.\n",
    "\n",
    "    reconstructed_brain = {}\n",
    "\n",
    "    for name, cnts3d in contours_atlasResol.iteritems():\n",
    "        reconstructed_brain[name] = interpolate_contours_to_volume(interpolation_direction='x',\n",
    "                                                        contours_xyz=cnts3d, \n",
    "                                                        len_interval=20.,\n",
    "                                                            return_origin_instead_of_bbox=True)\n",
    "\n",
    "        surround_name = convert_to_surround_name(name, margin='%dum' % surround_distance_um)\n",
    "\n",
    "        reconstructed_brain[surround_name] = \\\n",
    "        get_surround_volume_v2(vol=reconstructed_brain[name][0], origin=reconstructed_brain[name][1], \n",
    "                               wall_level=valid_level, distance=surround_distance_voxel, \n",
    "                               prob=True,\n",
    "                               return_origin_instead_of_bbox=True)\n",
    "\n",
    "    # display_volume_sections(reconstructed_brain['SNR_L'][0])\n",
    "\n",
    "    for s, v in reconstructed_brain.iteritems():\n",
    "        vol_fp = DataManager.get_original_volume_filepath_v2(stack_spec=dict(name=brain_name, \n",
    "                                                                         vol_type='annotationAsScore',\n",
    "                                                                resolution=out_resolution),\n",
    "\n",
    "                                            structure=s)\n",
    "        save_data(v[0], vol_fp)\n",
    "\n",
    "        origin_fp = DataManager.get_original_volume_origin_filepath_v3(stack_spec=dict(name=brain_name, \n",
    "                                                                         vol_type='annotationAsScore',\n",
    "                                                                        resolution=out_resolution),\n",
    "                                            structure=s)\n",
    "        save_data(v[1], origin_fp)\n",
    "\n",
    "    # Export markers.\n",
    "\n",
    "    for name, mkrs in markers_atlasResol.iteritems():\n",
    "        save_data(markers_atlasResol[name], \n",
    "                  DataManager.get_lauren_markers_filepath(stack=brain_name, structure=name, resolution='10.0um'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
